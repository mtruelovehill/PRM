---
title: "<b> Intro to Null-Hypothesis Statistical Testing </b>"
subtitle: "Psychological Research Methods:<br>Data Management & Analysis<br><br> "
author: "Monica Truelove-Hill"
institute: "Department of Clinical Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#18778C",
  header_color = "#000000",
  header_font_google = google_font("Jost"),
  header_font_weight = 500,
  text_font_google = google_font("Jost", "300", "300i", "500", "500i"),
  code_font_google = google_font("Source Code Pro"),
  text_bold_color = '#D95829',
  text_slide_number_color = '#18778C',
  text_font_size = '16pt'
)
```

```{r, echo = F, message = F, warning = F}
library(tidyverse)
knitr::opts_chunk$set(dev = 'svg')

baseColor <- "#18778C"
accent1 <- '#D95829'
accent2 <- '#BF3326'
accent3 <- '#F29422'

Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
```

## Why????

+ Psychology is a science....

--

+ with a lot of uncertainty

--

+ To answer our research questions, we rely on empirical evidence 

+ We take measurements that allow us to make systematic observations of our construct of interest, then use these observations to draw conclusions

+ In other words, we gather data and look for consistent patterns within the data that support (or refute) our ideas

+ But how do we decide what is *consistent enough*?

---

## Research process

```{r, echo = F}
knitr::include_graphics('images/ResearchProcess.png')
```

---
exclude: true
## The truth is out there.

---
## From sample to population

+ In statistics, we often refer to samples and populations
  
  + **Population:** The entire group about whom you're making inferences
  
  + **Sample:** The subset of the population from whom you will collect data to make these inferences
  
+ We typically use **sample statistics**, or **point-estimates** to make inferences about **population parameters**

---
## Hypotheses

+ **Null Hypothesis ( $H_0$ ):** There is no difference or effect, and any experimentally observed difference is due to chance

+ **Alternative Hypothesis ( $H_1$ ):** There is a relationship or association between variables

+ The burden of proof is on $H_1$

  + Assume $H_0$ is accurate until there is sufficient evidence that it is not
  
  + Tests of significance assess strength of the evidence against $H_0$

---
## Visualising your data: Frequency Distributions

+ Frequency distributions allow you to visualise how often each observation occurs

+ The type of frequency distribution you should use depends on the type of data you have:

--

.pull-left[
.center[**Categorical Data: Bar Plots**]
```{r, echo = F, fig.height=3.5, fig.width = 4.5}
set.seed(608)

dat <- data.frame(EyeColour = sample(c('Blue', 'Green', 'Hazel', 'Amber', 'Brown', 'Gray'), size = 1000, replace = T, 
                            prob = c(.10, .02, .05, .05, .75, .03)),
                  Age = rnorm(1000, 35, 10))

ecPlot <- ggplot(dat, aes(EyeColour, fill = as.factor(EyeColour))) + geom_bar() +
  scale_fill_manual(values = c('#D98825', '#6D90A6', '#592202', '#B8BDB6', '#4E7A23', '#716F3F')) +
  labs(x = 'Eye Colour', y = 'Count') +
  theme(legend.position = 'none',
        axis.text = element_text(size = 14),
        axis.title = element_text(size = 16, face = 'bold'))

ecPlot
```
]

.pull-right[
.center[**Continuous Data: Histograms**]
```{r, echo = F, fig.height=3.5, fig.width = 4.5, message = F}

ggplot(dat, aes(Age)) + geom_histogram(fill=baseColor, colour = 'darkgray') +
  labs(x = 'Age', y = 'Count') +
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 16, face = 'bold'))

```
]

---
## Describing your data: Central Tendancy

+ What is the middle-ish point of your data?

+ Can estimate in 3 ways:
  + **Mean**
  + **Median**
  + **Mode**
  
---
## Central Tendancy: Mean

.pull-left[


**The mathematical notation:**

$$\bar{x} = \frac{\displaystyle\sum_{i=1}^{n}x_i}{n}$$
+ Where:
    + $n$ = total number of values in the data
    + $x_i$ = an individual value in the data
    + $\displaystyle\sum_{i=1}^{n}$ = sum all values between 1 ( $i=1$ ) and $n$

]

---
count: false

## Central Tendancy: Mean

.pull-left[

**The mathematical notation:**

$$\bar{x} = \frac{\displaystyle\sum_{i=1}^{n}x_i}{n}$$
+ Where:
    + $n$ = total number of values in the data
    + $x_i$ = an individual value in the data
    + $\displaystyle\sum_{i=1}^{n}$ = sum all values between 1 ( $i=1$ ) and $n$

    
**In basic language:** 
 
 + The mathematical average; sum all values and divide by the total number of values
]

--

.pull-right.center[

$x = \{10, 2, 5, 3, 2, 0, 12\}$

$\bar{x} = \frac{\sum(10, 2, 5, 3, 2, 0, 12)}{7}$ 


$\bar{x} = 4.86$ 


```{r, echo = F, out.width='45%'}
knitr::include_graphics('images/SPSSmean.PNG')
```

]

---
## Central Tendancy: Mean

+ Can be used with _continuous/numeric_ data (i.e. interval and ratio data)

+ Shouldn't be used with nominal data, and it's best not used with ordinal data, even though they may be coded as numeric values


--


+ Say you have the following scale:

.pull-left[


| Scale  | Rate your understanding of the lecture     |
|--------|--------------------------------------------|
|    1   | I'm completely lost.                       |
|    2   | I'm a bit confused.                        |
|    3   | I understand about half of it.             |
|    4   | It's starting to come together.            |
|    5   | Everything is perfectly clear.             |

]

.pull-right[

> **Test your understanding:** What does a mean of 3.2 actually mean, in the context of this scale?

]

---
count: false

## Central Tendancy: Mean

+ Can be used with _continuous/numeric_ data (i.e. interval and ratio data)

+ Shouldn't be used with nominal data, and it's best not used with ordinal data, even though they may be coded as numeric values

+ Say you have the following scale:

.pull-left[


| Scale  | Rate your understanding of the lecture     |
|--------|--------------------------------------------|
|    1   | I'm completely lost.                       |
|    2   | I'm a bit confused.                        |
|    3   | I understand about half of it.             |
|    4   | It's starting to come together.            |
|    5   | Everything is perfectly clear.             |

]

.pull-right[

> **Test your understanding:** What does a mean of 3.2 actually mean, in the context of this scale?

> Is someone who is a bit confused twice as confused as someone for whom it's starting to come together?

]
---
## Central Tendancy: Median

+ The value in the exact center of a range

+ Can be used with ordinal, ratio, or interval data

.pull-left[
.center[
**If there are an odd number of values:**

$x = \{10, 2, 5, 3, 2, 0, 12\}$

$0, 2, 2, \color{#D95829}{3}, 5, 10, 12$

**Median $x$ = 3**

]
]


.pull-right[
.center[
**If there are an even number of values:**

$y = \{3, 7, 1, 20, 14, 25\}$


$1, 3, \color{#D95829}{7, 14,} 20, 25$


$\frac{7+14}{2} = 10.5$


**Median $y$ = 10.5**
]



]


---
## Central Tendancy: Mode

.pull-left[
+ The value that appears most frequently in a range

+ Can be used with all types of data, although may be less descriptive of continuous data depending on the precision of the measurement

+ Data may be bimodal or multimodal

```{r, echo = F, fig.height=3.5}
ecPlot
```

]

--

.pull-right.center[

$x = \{10, \color{#D95829}{2}, 5, 3, \color{#D95829}{2}, 0, 12\}$

```{r, echo = F, out.width='85%'}
knitr::include_graphics('images/SPSSmode.PNG')
```

]


---

####  How useful are the measures of central tendency in each of the following situations?

.pull-left.center[
```{r, echo = F, message = F, fig.height=2.5, fig.width=4}
set.seed(113)
x <- round(rnorm(250, 25, 20))
ggplot(mapping = aes(x)) + geom_histogram(fill = baseColor, color = 'darkgray', binwidth = 2) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  geom_vline(xintercept = mean(x), color = accent1) +
  geom_vline(xintercept = median(x), color = accent2) +
  geom_vline(xintercept = round(Mode(x)), color = accent3) +
  annotate('text', label = paste('Mean =', round(mean(x), 2)), color = accent1, x = 60, y = 18) +
  annotate('text', label = paste('Median =', round(median(x), 2)), color = accent2, x = 60, y = 16) +
  annotate('text', label = paste('Mode =', round(Mode(x))), color = accent3, x = 60, y = 14)
```

```{r, echo = F, message = F, fig.height=2.5, fig.width=4}
set.seed(926)
y <- round(rnorm(250, 25, 3))
ggplot(mapping = aes(y)) + geom_histogram(fill = baseColor, color = 'darkgray', binwidth = 2) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  geom_vline(xintercept = mean(y), color = accent1) +
  geom_vline(xintercept = median(y), color = accent2) +
  geom_vline(xintercept = round(Mode(y)), color = accent3) +
  annotate('text', label = paste('Mean =', round(mean(y), 2)), color = accent1, x = 30, y = 55) +
  annotate('text', label = paste('Median =', round(median(y), 2)), color = accent2, x = 30, y = 50) +
  annotate('text', label = paste('Mode =', round(Mode(y))), color = accent3, x = 30, y = 45)
```
]

.pull-right.center[
```{r, echo = F, message = F, fig.height=2.5, fig.width=4}
set.seed(1022)
z <- round(runif(100, 0, 10))
ggplot(mapping = aes(z)) + geom_histogram(fill = baseColor, color = 'darkgray', binwidth = 1) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  geom_vline(xintercept = mean(z), color = accent1) +
  geom_vline(xintercept = median(z), color = accent2) +
  geom_vline(xintercept = round(Mode(z)), color = accent3) +
  annotate('text', label = paste('Mean =', round(mean(z), 2)), color = accent1, x = 9 , y = 17) +
  annotate('text', label = paste('Median =', round(median(z), 2)), color = accent2, x = 9 , y = 15.5) +
  annotate('text', label = paste('Mode =', round(Mode(z))), color = accent3, x = 9 , y = 14)
```

```{r, echo = F, message = F, fig.height=2.5, fig.width=4}
set.seed(526)
a <- rbeta(100, 10, .5)
ggplot(mapping = aes(a)) + geom_histogram(fill = baseColor, color = 'darkgray', binwidth = .01) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  geom_vline(xintercept = mean(a), color = accent1) +
  geom_vline(xintercept = median(a), color = accent2) +
  geom_vline(xintercept = round(Mode(a),2), color = accent3) +
  annotate('text', label = paste('Mean =', round(mean(a), 2)*315), color = accent1, x = .75, y = 17) +
  annotate('text', label = paste('Median =', round(median(a), 2)*315), color = accent2, x = .75 , y = 15) +
  annotate('text', label = paste('Mode =', round(Mode(a),2)*315), color = accent3, x = .75, y = 13)
```

]


---
## Limitations of Central Tendency

+ In isolation, central tendency doesn't sufficiently describe the data

.pull-left[

| Participant |  Test Score |
|:-----------:|:-----------:|
| 1           |    6        |
| 2           |    5        |
| 3           |    6        |
| 4           |    5        |
| 5           |    5        |
| Total       |    27       |

.center[
**Mean = 5.4**
]

]

.pull-right[

| Participant |  Test Score |
|:-----------:|:-----------:|
| 1           |    2        |
| 2           |    2        |
| 3           |    10       |
| 4           |    10       |
| 5           |    3        |
| Total       |    27       |

.center[
**Mean = 5.4**
]

]

---
## Variation in Scores

.pull-left[
+ Helps us to understand how well the mean describes our data

+ Can estimate this using:

  + Maxima & Minima
  
  + Range
  
  + Interquartile Range

  + Variance
  
  + Standard Deviation
]


--


.pull-right[
```{r, echo = F, fig.height=5}
set.seed(208)
sampDat <- data.frame(Participant = as.factor(1:12), Age=round(sample(dat$Age, 12)))
sampDat$Age[sampDat$Participant=='12'] <- 33
varPlot <- ggplot(sampDat, aes(Participant, Age)) + geom_point(size = 2.5) +
  scale_y_continuous(breaks=seq(15, 45, 5), limits = c(15, 45)) +
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 16, face = 'bold'))

varPlot
  
```
]


---
## Variation in Scores

.pull-left[
+ Helps us to understand how well the mean describes our data

+ Can estimate this using:

  + **Maxima & Minima**
  
  + Range
  
  + Interquartile Range

  + Variance
  
  + Standard Deviation
]


.pull-right[
```{r, echo = F, fig.height=5}

varPlot + annotate(geom = 'rect', xmin = which.min(sampDat$Age)-.5, xmax = which.min(sampDat$Age)+.5, ymin = min(sampDat$Age)-2, ymax = min(sampDat$Age)+2, alpha = .1, color = accent3) + 
  annotate('text', label = paste0('Minimum Value = ', round(min(sampDat$Age),2)), x = which.min(sampDat$Age)-3, y = min(sampDat$Age), size = 6) + 
  annotate(geom = 'rect', xmin = which.max(sampDat$Age)-.5, xmax = which.max(sampDat$Age)+.5, ymin = max(sampDat$Age)-2, ymax = max(sampDat$Age)+2, alpha = .1, color = accent3) + 
  annotate('text', label = paste0('Maximum Value = ', round(max(sampDat$Age),2)), x = which.max(sampDat$Age)-3, y = max(sampDat$Age), size = 6)
  
  
```
]

---
## Variation in Scores

.pull-left[
+ Helps us to understand how well the mean describes our data

+ Can estimate this using:

  + Maxima & Minima
  
  + **Range**
  
  + Interquartile Range

  + Variance
  
  + Standard Deviation
]


.pull-right[
```{r, echo = F, fig.height=5}

varPlot + 
  annotate(geom = 'rect', xmin = which.min(sampDat$Age)-.5, xmax = which.min(sampDat$Age)+.5, ymin = min(sampDat$Age)-2, ymax = min(sampDat$Age)+2, alpha = .1, color = accent3) + 
  annotate('text', label = paste0('Range = ', round(min(sampDat$Age),2), ' - ', round(max(sampDat$Age), 2)), x = 10, y = 45, size = 6) +
  annotate(geom = 'rect', xmin = which.max(sampDat$Age)-.5, xmax = which.max(sampDat$Age)+.5, ymin = max(sampDat$Age)-2, ymax = max(sampDat$Age)+2, alpha = .1, color = accent3) +
  annotate(geom = 'segment', x = 12.5, xend = 12.5, y = min(sampDat$Age), yend = max(sampDat$Age), color = accent3) +
  annotate(geom = 'segment', x = 11.5, xend = 12.5, y = max(sampDat$Age), yend = max(sampDat$Age), color = accent3, linetype = 'dashed') + 
  annotate(geom = 'segment', x = 6.5, xend = 12.5, y = min(sampDat$Age), yend = min(sampDat$Age), color = accent3, linetype = 'dashed')
  
```
]

---
## Variation in Scores - Interquartile Range

.pull-left[
+ Interquartile Range (IQR) tells you about the spread in the middle range of your data

+ It allows you to get a sense of variation in your data, excluding the most extreme values

+ This metric depends on the order of the values in the data, so note that the plot has been reordered based on Age. 

+ **NOTE:** The IQR is a key component of a boxplot, which we will return to later in the course
]


.pull-right[


```{r, echo = F, fig.height=5}
roDat <- sampDat
roDat$Participant <- factor(roDat$Participant, levels = sampDat$Participant[order(sampDat$Age)])

iqrPlot <- ggplot(roDat, aes(Participant, Age)) + geom_point() +
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 16, face = 'bold'))

iqrPlot 
```
]

---
## Variation in Scores - Interquartile Range

.pull-left[
+ First, calculate the median of your data

  + In our case, the median is the average of 31 and 33
  
  + This becomes our 2nd Quartile (Q2)

]


.pull-right[

```{r, echo = F, fig.height=5}

iqrPlot <- iqrPlot +  annotate('text', label = 'Q2 (median) = 32', x = 3, y = 32.5, color = baseColor, size = 6) +
  geom_hline(yintercept = median(roDat$Age), color = baseColor)

iqrPlot 
```
]

---
count: false

## Variation in Scores - Interquartile Range

.pull-left[
+ First, calculate the median of your data

  + In our case, the median is the average of 31 and 33
  
  + This becomes our 2nd Quartile (Q2)

+ Q4 = the maximum value in your data

]


.pull-right[


```{r, echo = F, fig.height=5}
iqrPlot <- iqrPlot + geom_hline(yintercept = max(roDat$Age), color = accent1) +
  annotate('text', label = paste0('Q4 (max) = ', max(roDat$Age)), x = 2.75, y = max(roDat$Age)+.5, color = accent1, size = 6)

iqrPlot
```
]

---
## Variation in Scores - Interquartile Range


.pull-left[
+ Next, calculate the remaining quartiles of your data

  + There are several ways to do this, and all will give you slightly different outcomes
  
  + This method uses *Tukey's Hinges*:
     
     + With an **even** number of observations:
        
        + Split the data in half at Q2.
        
        + Identify the median of all values below Q2. This is Q1.
        
        + The median of all values above Q2 is Q3.
]

.pull-right[

```{r, echo = F, fig.height=5}

ageOrder <- roDat$Age[order(roDat$Age)]
Q1 <- median(ageOrder[1:6])
Q3 <- median(ageOrder[7:12])

iqrPlot <- iqrPlot + 
  geom_hline(yintercept = Q1, color = accent2) +
  annotate('text', label = paste0('Q1 = ', Q1), x = 2.35, y = Q1+.5, color = accent2, size = 6) +
  geom_hline(yintercept = Q3, color = accent3) +
  annotate('text', label = paste0('Q3 = ', Q3), x = 2.35, y = Q3+.5, color = accent3, size = 6)

iqrPlot
```


]   

---
## Variation in Scores - Interquartile Range


.pull-left[
+ Next, calculate the remaining quartiles of your data

  + There are several ways to do this, and all will give you slightly different outcomes
  
  + This method uses *Tukey's Hinges*:
     
     + With an **odd** number of observations:
        
        + Split the data in half at Q2.
        
        + Q1 is the median of all values below Q2, including Q2.
        
        + Q3 is the median of all values above Q2, including Q2.
]

.pull-right[

```{r, echo = F, fig.height=5}

ageOrder <- roDat$Age[order(roDat$Age)]
Q1 <- median(ageOrder[1:6])
Q3 <- median(ageOrder[7:12])

iqrPlot <- iqrPlot + 
  geom_hline(yintercept = Q1, color = accent2) +
  annotate('text', label = paste0('Q1 = ', Q1), x = 2.35, y = Q1+.5, color = accent2, size = 6) +
  geom_hline(yintercept = Q3, color = accent3) +
  annotate('text', label = paste0('Q3 = ', Q3), x = 2.35, y = Q3+.5, color = accent3, size = 6)

iqrPlot
```


]   
---
## Variation in Scores - Interquartile Range


.pull-left[
+ Finally, calculate the IQR
      
     + $IQR=Q3-Q1$
     
     + $`r Q3` - `r Q1` = `r Q3-Q1`$
     

```{r, echo = F}
knitr::include_graphics('images/TukeysHinges.png')
```


]

.pull-right[

```{r, echo = F, fig.height=5}
iqrPlot
```


]   

---
## Variation in Scores - Variance

.pull-left[

$$s^2 = \frac{\sum(x_i-\bar{x})^2}{n-1}$$
]

.pull-right[
```{r, echo = F, fig.height=4.5}
varPlot
```

]


---
## Variation in Scores - Variance

.pull-left[

$$s^2 = \frac{\sum(\color{#D95829}{x_i}-\bar{x})^2}{n-1}$$

+ $x_i$ = individual observations of x
]

.pull-right[
```{r, echo = F, fig.height=4.5}
varPlot + geom_point(color = accent1, size = 3)
```

]

---
## Variation in Scores - Variance

.pull-left[
$$s^2 = \frac{\sum(x_i-\color{#D95829}{\bar{x}})^2}{n-1}$$


+ $x_i$ = individual observations of x

+ $\bar{x}$ = mean of variable x

]

.pull-right[
```{r, echo = F, fig.height=4.5}
varPlot <- varPlot + geom_hline(yintercept = mean(sampDat$Age), color = accent2)
varPlot
```

]

---
## Variation in Scores - Variance

.pull-left[
$$s^2 = \frac{\sum(\color{#D95829}{x_i-\bar{x}})^2}{n-1}$$


+ $x_i$ = individual observations of x

+ $\bar{x}$ = mean of variable x

]

.pull-right[
```{r, echo = F, fig.height=4.5}
sampDat$dist <- sampDat$Age-mean(sampDat$Age)

varPlot + geom_segment(aes(x = Participant, y = Age, xend = Participant, yend = mean(Age)),
               col = baseColor, lty = 2) + 
  annotate(geom='text', label=sampDat$dist, x=1:12+.5, y = sampDat$Age-sampDat$dist*.5, size=4.5)

```

]

---
## Variation in Scores - Variance

.pull-left[
$$s^2 = \frac{\sum(x_i-\bar{x})\color{#D95829}{^2}}{n-1}$$


+ $x_i$ = individual observations of x

+ $\bar{x}$ = mean of variable x

> **Test Your Understanding:** Why do we need to square these values before summing them?

]

.pull-right[
```{r, echo = F, fig.height=4.5}
sampDat$sqDist <- round(sampDat$dist^2,2)

varPlot + geom_segment(aes(x = Participant, y = Age, xend = Participant, yend = mean(Age)),
               col = baseColor, lty = 2) + 
  annotate(geom='text', label=sampDat$sqDist, x=1:12+.5, y = sampDat$Age-sampDat$dist*.5, size=4.5)

```

]

---
## Variation in Scores - Variance

.pull-left[
$$s^2 =\frac{\sum(x_i-\bar{x})^2}{n-1}$$


+ $x_i$ = individual observations of x

+ $\bar{x}$ = mean of variable x

+ $\sum(x_i-\bar{x})^2$ = sum of squared deviations (AKA the sum of squares)

+ $s^2 = \frac{`r round(sum(sampDat$sqDist), 2)`}{12-1} = `r round(sum(sampDat$sqDist)/(nrow(sampDat)-1),2)`$

]

.pull-right[
```{r, echo = F, fig.height=4.5}
varPlot + geom_segment(aes(x = Participant, y = Age, xend = Participant, yend = mean(Age)),
               col = baseColor, lty = 2) + 
  annotate(geom='text', label=sampDat$sqDist, x=1:12+.5, y = sampDat$Age-sampDat$dist*.5, size=4.5)
```

]

---
## Why n-1?

+ Recall that we are using a sample to make estimates about the overall population

+ In doing so, we are assuming that our sample mean reflects the population mean

+ Adding -1 allows us to make an estimate of the population variance that's less biased by our specific sample.

--

> **Test your understanding:** Is a smaller sample MORE or LESS likely to reflect the overall population?

--

.pull-left[
+ Imagine that we have calculated the sum of squares to be 127
]

.pull-right[

| Sample Size | Variance (n)          | Variance (n - 1)     |
|:-----------:|:---------------------:|:--------------------:|
|    5        |  `r round(127/5, 2)`  | `r round(127/4, 2)`  |
|    10       |  `r round(127/10,2)`  | `r round(127/9, 2)`  |
|    50       |  `r round(127/50,2)`  | `r round(127/49,2)`  |
|    100      |  `r round(127/100,2)` | `r round(127/99,2)`  |
|    1000     |  `r round(127/1000,2)`| `r round(127/999,2)` |

]


???

Probably a wider spread in the population than what we are accounting for in our small sample

As the sample grows larger, the variance estimated using n or n-1 grows more similar


---
## Variation in Scores - Standard Deviation

.pull-left[
$$SD =\sqrt\frac{\sum(x_i-\bar{x})^2}{n-1}$$
+ On average, how far away are individual observations from the mean? 

+ Expressed in the units of the variable of interest

+ $SD = \sqrt{`r round(sum(sampDat$sqDist)/(nrow(sampDat)-1),2)`} = `r round(sqrt(sum(sampDat$sqDist)/(nrow(sampDat)-1)),2)`$

+ On average, participants in our sample are `r round(sqrt(sum(sampDat$sqDist)/(nrow(sampDat)-1)),2)` years older or younger than the mean of `r round(mean(sampDat$Age),2)`.

]

--

.pull-right.center[
**Mean = 10, SD = 1**
```{r, echo = F, fig.height=2, fig.width=4}
set.seed(444)
f <- rnorm(200, 10, 1)
ggplot(mapping=aes(f)) + geom_histogram(fill = baseColor, color = 'darkgray', bins=15) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  geom_vline(xintercept = mean(f), color = accent1)
```

**Mean = 10, SD = 10**

```{r, echo = F, fig.height=2, fig.width=4}
set.seed(602)
m <- rnorm(200, 10, 10)
ggplot(mapping=aes(m)) + geom_histogram(fill = baseColor, color = 'darkgray', bins=15) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  geom_vline(xintercept = mean(m), color = accent1)

```

]


---
## Why SD? Why not just variance?

+ To illustrate this, let's look at an example with distance in miles and the corresponding values in kilometers:

```{r, echo=F}
distDat <- data.frame(miles=c(4.25, 2.61, 1.13, 5.89, 8.60))
distDat$km <- round(distDat$miles*1.61,2)
ssMiles <- round(sum((distDat$miles-mean(distDat$miles))^2),2)
ssKm <- round(sum((distDat$km-mean(distDat$km))^2),2)
s2Miles <- round(var(distDat$miles), 2)
s2Km <- round(var(distDat$km), 2)
sdMiles <- round(sd(distDat$miles),2)
sdKm <- round(sd(distDat$km),2)
```


.pull-left[

| Miles | Kilometers|
|:-----:|:---------:|
| 4.25 | 6.84       |
| 2.61 | 4.20       |
| 1.13 | 1.82       |
| 5.89 | 9.48       |
| 8.60 | 13.85      |

+ Miles = km/1.61

]

--

.pull-right[

| Statistic         | Miles       | Kilometers |
|:-----------------:|:-----------:|:----------:|
|  $Sum\ of\ Squares$ | `r ssMiles` | `r ssKm`   |
|    $s^2$          | `r s2Miles` | `r s2Km`   |


]


---
count: false

## Why SD? Why not just variance?

+ To illustrate this, let's look at an example with distance in miles and the corresponding values in kilometers:

.pull-left[

| Miles | Kilometers|
|:-----:|:---------:|
| 4.25 | 6.84       |
| 2.61 | 4.20       |
| 1.13 | 1.82       |
| 5.89 | 9.48       |
| 8.60 | 13.85      |

+ Miles = km/1.61

]

.pull-right[

| Statistic         | Miles       | Kilometers |
|:-----------------:|:-----------:|:----------:|
|  $Sum\ of\ Squares$ | `r ssMiles` | `r ssKm`   |
|    $s^2$          | `r s2Miles` | `r s2Km`   |

+ $`r s2Km`/1.6 = `r round(s2Km/1.6, 2)`$

+ $`r round(s2Km/1.6, 2)` \neq `r s2Miles`$ 

+ Variance values are **not in the same units as the original data**, so they won't conform to the same rules

+ This also affects interpretability

]


---
## Why SD? Why not just variance?

+ To illustrate this, let's look at an example with distance in miles and the corresponding values in kilometers:

.pull-left[

| Miles | Kilometers|
|:-----:|:---------:|
| 4.25 | 6.84       |
| 2.61 | 4.20       |
| 1.13 | 1.82       |
| 5.89 | 9.48       |
| 8.60 | 13.85      |

+ Miles = km/1.61

]

.pull-right[

| Statistic         | Miles       | Kilometers |
|:-----------------:|:-----------:|:----------:|
|  $Sum\ of\ Squares$ | `r ssMiles` | `r ssKm`   |
|    $s^2$          | `r s2Miles` | `r s2Km`   |
|    $SD$           | 2.91 | `r sdKm`   |

]

---
count: false

## Why SD? Why not just variance?

+ To illustrate this, let's look at an example with distance in miles and the corresponding values in kilometers:

.pull-left[

| Miles | Kilometers|
|:-----:|:---------:|
| 4.25 | 6.84       |
| 2.61 | 4.20       |
| 1.13 | 1.82       |
| 5.89 | 9.48       |
| 8.60 | 13.85      |

+ Miles = km/1.61

]

.pull-right[

| Statistic         | Miles       | Kilometers |
|:-----------------:|:-----------:|:----------:|
|  $Sum\ of\ Squares$ | `r ssMiles` | `r ssKm`   |
|    $s^2$          | `r s2Miles` | `r s2Km`   |
|    $SD$           | 2.91 | `r sdKm`   |

+ $`r sdKm`/1.61 = `r round(sdKm/1.61, 2)`$

+ $`r round(sdKm/1.61, 2)` = 2.91$ 

+ This now works, because SD values are measured in the same units as the original data
]

---
## A Note on Notation

+ We use slightly different notations when referring to point-estimates versus population parameters:

.center[

| Value              | Population | Sample          |
|:------------------:|:----------:|:---------------:|
| Mean               |  $\mu$     | $M$ or $\bar{x}$|
| Standard Deviation | $\sigma$   | $SD$ or $s$     |
| Sample Size        | $N$        | $n$             |

]


---
class: center, inverse, middle

## Questions?

---
## Describing your data: Probability distributions

.pull-left[

+ A probability distribution is a way to visualise the probability of specific observations

+ These distributions give us an idea of how unusual or rare a specific observation is

+ Specifically, we can compute the probability of a specific range of values within a distribution
]


.pull-right[

```{r, echo = F, fig.height=3.5}
ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
  stat_function(fun=dnorm, geom = "line", linewidth = 1.5) + 
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14, face = 'bold'),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank()) +
  geom_hline(yintercept = 0, linewidth = 1.5)

```


]

--

> **Test Your Understanding:** Which value of x is most common, according to the probability distribution seen here? Which values are less common?

---
## The normal distribution

+ A probability distribution where values around the mean are most common, and values further from the mean are increasingly less common.

+ AKA the bell curve, a Gaussian distribution

--

> **Test Your Understanding:** What kinds of variables can you think of that might follow a normal distribution? 

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Centered around mean

]
.pull-right[
```{r, echo = F, fig.width=5, fig.height=3.5}
normDist <- ggplot(data.frame(X = c(-6, 6)), aes(x = X)) +
  stat_function(fun=dnorm, geom = "line", linewidth = 1.5) + 
  theme(axis.title.x = element_text(size = 14, face = 'bold'),
        axis.line.y = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title.y = element_blank())

normDist + geom_vline(xintercept = 0, color=accent1)
```
]

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Centered around mean

  + **68%** of scores fall within **1 SD** of the mean

]
.pull-right[
```{r, echo = F, fig.width=5, fig.height=3.5}
normDist + geom_area(stat = 'function', fun = dnorm, fill = baseColor, xlim=c(-1, 1), alpha = .7) + 
  geom_vline(xintercept = 0, color=accent1)
```
]

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Centered around mean

  + 68% of scores fall within 1 SD of the mean
  + **95%** of scores fall within **~2 SD** of the mean (exactly 1.96 SD of the mean)

]
.pull-right[
```{r, echo = F, fig.width=5, fig.height=3.5}
normDist + geom_area(stat = 'function', fun = dnorm, fill = accent3, xlim=c(-1.96, 1.96), alpha = .7) + 
  geom_vline(xintercept = 0, color=accent1)
```
]

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Centered around mean

  + 68% of scores fall within 1 SD of the mean
  + 95% of scores fall within ~2 SD of the mean (exactly 1.96 SD of the mean)
  + **99.75%** of scores fall within **3 SD** of the mean

]
.pull-right[
```{r, echo = F, fig.width = 5, fig.height = 3.5}
normDist + geom_area(stat = 'function', fun = dnorm, fill = accent2, xlim=c(-3, 3), alpha = .7) +
  geom_vline(xintercept = 0, color=accent1)
```
]

---
## The normal distribution

> **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
```{r, echo = F, fig.width=8, fig.height=4}

set.seed(22)
waisDat <- data.frame(Score=rnorm(1000, mean = 100, sd = 15))

waisDist <- ggplot(data.frame(X=c(-4, 4)), aes(x=X)) + 
  stat_function(fun=dnorm, geom = "line", linewidth = 1.5, args = c(mean=0, sd =1)) +
  geom_hline(yintercept = 0, linewidth = 1.5) +
  xlab('WAIS Score') +
  theme(axis.title.x = element_text(size = 14, face = 'bold'),
        axis.line.y = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title.y = element_blank())

waisDist + 
  annotate(geom='segment', x=0, xend=0, y=0, yend=.4, color = accent1, linetype='dashed', linewidth = 1) +
  annotate(geom='text', label = 'A', x=0, y = -.02, color = accent1, size = 5)
```
]

---
## The normal distribution

> **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
```{r, echo = F, fig.width=8, fig.height=4}

waisDist <- waisDist + 
  annotate(geom='text', label = '100', x = 0, y = -.02, size = 5, color = accent1) +
  annotate(geom='segment', x=0, xend=0, y=.01, yend=-.01)

waisDist + 
  geom_area(stat = 'function', fun = dnorm, fill = baseColor, xlim=c(-1, 1), alpha = .7) +
  annotate(geom='segment', x=-1, xend=-1, y=0, yend=.4, color = baseColor, linetype='dashed', linewidth = 1) +
  annotate(geom='segment', x=1, xend=1, y=0, yend=.4, color = baseColor, linetype='dashed', linewidth = 1) +
  annotate(geom = 'text', label = '~68%', x = 0, y = .2, color='white', size = 7) +
  annotate(geom='text', label = 'C', x=1, y = -.02, color = baseColor, size = 5) +
  annotate(geom='text', label = 'B', x=-1, y = -.02, color = baseColor, size = 5)
  
```
]

---
## The normal distribution

> **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
```{r, echo = F, fig.width=8, fig.height=4}

waisDist <- waisDist + 
  annotate(geom='text', label = '85', x = -1, y = -.02, size = 5, color = baseColor) +
  annotate(geom='segment', x=-1, xend=-1, y=.01, yend=-.01) +
  annotate(geom='text', label = '115', x = 1, y = -.02, size = 5, color = baseColor) +
  annotate(geom='segment', x=1, xend=1, y=.01, yend=-.01)
  

waisDist + 
  geom_area(stat = 'function', fun = dnorm, fill = accent3, xlim=c(-1.96, 1.96), alpha = .7) +  
  annotate(geom='segment', x=-1.96, xend=-1.96, y=0, yend=.4, color = accent3, linetype='dashed', linewidth = 1) +
  annotate(geom='segment', x=1.96, xend=1.96, y=0, yend=.4, color = accent3, linetype='dashed', linewidth = 1) +
  annotate(geom = 'text', label = '~95%', x = 0, y = .2, color='white', size = 7) +
  annotate(geom='text', label = 'E', x= 1.96, y = -.02, color = accent3, size = 5) +
  annotate(geom='text', label = 'D', x=-1.96, y = -.02, color = accent3, size = 5)
  
```
]

---

## The normal distribution

> **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
```{r, echo = F, fig.width=8, fig.height=4}

waisDist <- waisDist + 
  annotate(geom='text', label = '70', x = -1.96, y = -.02, size = 5, color = accent3) +
  annotate(geom='segment', x=-1.96, xend=-1.96, y=.01, yend=-.01) +
  annotate(geom='text', label = '130', x = 1.96, y = -.02, size = 5, color = accent3) +
  annotate(geom='segment', x=1.96, xend=1.96, y=.01, yend=-.01)
  

waisDist + 
  geom_area(stat = 'function', fun = dnorm, fill = accent2, xlim=c(-3, 3), alpha = .7) +
  annotate(geom = 'text', label = '~99%', x = 0, y = .2, color='white', size = 7) +
  annotate(geom='segment', x=-3, xend=-3, y=0, yend=.4, color = accent2, linetype='dashed', linewidth = 1) +
  annotate(geom='segment', x=3, xend=3, y=0, yend=.4, color = accent2, linetype='dashed', linewidth = 1) +
  annotate(geom='text', label = 'G', x=-3, y = -.02, color = accent2, size = 5) +
  annotate(geom='text', label = 'F', x=3, y = -.02, color = accent2, size = 5)
  
```
]

---
## The normal distribution

> **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
```{r, echo = F, fig.width=8, fig.height=4}

waisDist <- waisDist + 
  annotate(geom='text', label = '55', x = -3, y = -.02, size = 5, color = accent2) +
  annotate(geom='segment', x=-3, xend=-3, y=.01, yend=-.01) +
  annotate(geom='text', label = '145', x = 3, y = -.02, size = 5, color = accent2) +
  annotate(geom='segment', x=3, xend=3, y=.01, yend=-.01)
  

waisDist + 
  annotate(geom='text', label = 'Mean', x = 0, y = -.045, size = 5, color = accent1) +
  annotate(geom='text', label = '-1 SD', x = -1, y = -.045, size = 5, color = baseColor) +
  annotate(geom='text', label = '+1 SD', x = 1, y = -.045, size = 5, color = baseColor) +
  annotate(geom='text', label = '-~2 SD', x = -1.96, y = -.045, size = 5, color = accent3) +
  annotate(geom='text', label = '+~2 SD', x = 1.96, y = -.045, size = 5, color = accent3) +
  annotate(geom='text', label = '-3 SD', x = -3, y = -.045, size = 5, color = accent2) +
  annotate(geom='text', label = '+3 SD', x = 3, y = -.045, size = 5, color = accent2) +
  annotate(geom='segment', x=-3, xend=-3, y=0, yend=.01, color = accent2, linetype='dashed', linewidth = 1) +
  annotate(geom='segment', x=3, xend=3, y=0, yend=.01, color = accent2, linetype='dashed', linewidth = 1) +   
  annotate(geom='segment', x=-1.96, xend=-1.96, y=0, yend=.06, color = accent3, linetype='dashed', linewidth = 1) +
  annotate(geom='segment', x=1.96, xend=1.96, y=0, yend=.06, color = accent3, linetype='dashed', linewidth = 1) + 
  annotate(geom='segment', x=-1, xend=-1, y=0, yend=.25, color = baseColor, linetype='dashed', linewidth = 1) +
  annotate(geom='segment', x=1, xend=1, y=0, yend=.25, color = baseColor, linetype='dashed', linewidth = 1) +
  annotate(geom='segment', x=0, xend=0, y=0, yend=.4, color = accent1, linetype='dashed', linewidth = 1)
```
]
---
## Describing your data: Probability distributions

.pull-left[

+ We can also use probability distributions to compute the probability of value beyond a specific point on the distribution. 

+ Imagine we have a range of observations whose values fall between 8 and 32 that are distributed as pictured.

+ Let's say we randomly select an observation from our dataset.

]

.pull-right[
```{r, echo = F, fig.height=3.5}
testDat <- ggplot(data.frame(x = c(8, 32)), aes(x = x)) +
  stat_function(fun=dnorm, args= list(20, 3), geom = "line", linewidth = 1.5) +
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14, face = 'bold'),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank()) +
  geom_hline(yintercept = 0, linewidth = 1.5)

testDat
```
]

---
## Describing your data: Probability distributions

.pull-left[

+ We can also use probability distributions to compute the probability of value beyond a specific point on the distribution.

+ Imagine we have a range of observations whose values fall between 8 and 32 that are distributed as pictured.

+ Let's say we randomly select an observation from our dataset.

+ What is the likelihood our randomly selected observation is at least 25?

]

.pull-right[

```{r, echo = F, fig.height=3.5}
testDat + 
    geom_vline(xintercept = 25, color = accent3, linewidth = 1.5)
```

]


---
count: false

## Describing your data: Probability distributions

.pull-left[

+ We can also use probability distributions to compute the probability of value beyond a specific point on the distribution.

+ Imagine we have a range of observations whose values fall between 8 and 32 that are distributed as pictured.

+ Let's say we randomly select an observation from our dataset.

+ What is the likelihood our randomly selected observation is at least 25?

+ ~95% of our observations are less than 25. This means we only have about a 5% chance of randomly selecting an observation of at least 25. 

]

.pull-right[

```{r, echo = F, fig.height=3.5}
testDat + 
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = baseColor, xlim=c(8, 25), alpha = .8) +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = accent2, xlim=c(25, 30), alpha = .8) +
  annotate('text', label = '95%', x = 20, y = .05, color = 'white', size = 7) + 
  annotate('text', label = '5%', x = 26, y = .01, color = 'white', size = 7) +
  geom_vline(xintercept = 25, color = accent3, linewidth = 1)
```
]

---
## Probability Distributions

+ Why does this matter?

--

+ Many of the statistical tests we will learn about in this course all involve testing the probability of a specific value of a test statistic, given that $H_0$ is true. 

+ In other words, if $H_0$ is true, how likely is it that we would get results at least as extreme as ours?

+ If the value is unusual enough (i.e., if it is highly unlikely we would see the value if the null is true), we reject $H_0$

---
class: center, inverse, middle

## Questions?

---
## Null Distribution

+ All parametric quantitative tests we learn about in this course evaluate significance by evaluating results against a predefined **null distribution**

+ The null distribution is the probability distribution of a statistic **given that $H_0$ is true**. 

+ The shape of the null distribution depends on the test statistic (and the degrees of freedom, which we'll get to at a later point in the course)


---
## Comparing Data against null distribution: NHST

.pull-left[
```{r, echo = F, fig.height=5}
testDat
```

]


---
count: false

## Comparing Data against null distribution: NHST

.pull-left[

```{r, echo = F, fig.height=5}
testDat + geom_vline(xintercept = 24, color = accent1, linewidth = 1.5)
```

]

.pull-right[
```{r, echo = F, fig.height=5}
testDat + geom_vline(xintercept = 18, color = accent3, linewidth = 1.5)
```

]

> **Test Your Understanding:** Which score is less common?

---
count: false

## Comparing Data against null distribution: NHST

.pull-left[
```{r, echo = F, fig.height=5}
testDat +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = baseColor, xlim=c(8, 24), alpha = .8) +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = accent2, xlim=c(24, 30), alpha = .8) +
  annotate('text', label = '91%', x = 18, y = .02, color = 'white', size = 7) + 
  annotate('text', label = '9%', x = 25, y = .02, color = 'white', size = 7)+ 
  geom_vline(xintercept = 24, color = accent1, linewidth = 1.5)
```
]

.pull-right[
```{r, echo = F, fig.height=5}
testDat +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = accent2, xlim=c(8, 18), alpha = .8) +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = baseColor, xlim=c(18, 30), alpha = .8) +
  annotate('text', label = '25%', x = 16, y = .02, color = 'white', size = 7) + 
  annotate('text', label = '75%', x = 22, y = .02, color = 'white', size = 7) + 
  geom_vline(xintercept = 18, color = accent3, linewidth = 1.5)
```
]

> **Test Your Understanding:** Which score is less common?


---

## Null Distributions

.pull-left[
```{r, echo = F, fig.height=2.5, fig.width=4.5}
ggplot(data.frame(x=c(0, 10)), aes(x=x)) +
  stat_function(fun=dchisq, geom='line', args=c(df = 1), color = baseColor, linewidth=1.5) +
  stat_function(fun=dchisq, geom='line', args=c(df = 2), color = accent1, linewidth=1.5) +
  stat_function(fun=dchisq, geom='line', args=c(df = 3), color = accent2, linewidth=1.5) +
  stat_function(fun=dchisq, geom='line', args=c(df = 4), color = accent3, linewidth=1.5) +
  scale_y_continuous(limits=c(0, .52), breaks = seq(0, .5, .1)) +
  annotate('text', label = 'df = 1', color = baseColor, x = 8, y = .45, size = 5) +
  annotate('text', label = 'df = 2', color = accent1, x = 8, y = .38, size = 5) +
  annotate('text', label = 'df = 3', color = accent2, x = 8, y = .31, size = 5) +
  annotate('text', label = 'df = 4', color = accent3, x = 8, y = .24, size = 5) +
  labs(x = expression(chi^2)) +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 16, face = 'bold'),
        axis.text.x = element_text(size = 14))

```
]


.pull-right[
```{r, echo = F, fig.height=2.5, fig.width=4.5}
ggplot(data.frame(x=c(-6, 6)), aes(x=x)) +
  stat_function(fun=dt, geom='line', args=c(df = 5), color = baseColor, linewidth=1.5) +
  stat_function(fun=dt, geom='line', args=c(df = 10), color = accent1, linewidth=1.5) +
  stat_function(fun=dt, geom='line', args=c(df = 20), color = accent2, linewidth=1.5) +
  stat_function(fun=dt, geom='line', args=c(df = 50), color = accent3, linewidth=1.5) +
  annotate('text', label = 'df = 5', color = baseColor, x = 3, y = .4, size = 5) +
  annotate('text', label = 'df = 10', color = accent1, x = 3, y = .35, size = 5) +
  annotate('text', label = 'df = 20', color = accent2, x = 3, y = .3, size = 5) +
  annotate('text', label = 'df = 50', color = accent3, x = 3, y = .25, size = 5) +
  labs(x = 't-statistic') +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 16, face = 'bold'),
        axis.text.x = element_text(size = 14))

```
]

.center[
```{r, echo = F, fig.height=2.5, fig.width=4.5}
ggplot(data.frame(x=c(0, 5)), aes(x=x)) +
  stat_function(fun=df, geom='line', args=c(df1 = 2, df2=10), color = baseColor, linewidth=1.5) +
  stat_function(fun=df, geom='line', args=c(df1 = 5, df2=10), color = accent1, linewidth=1.5) + 
  stat_function(fun=df, geom='line', args=c(df1 = 5, df2=100), color = accent2, linewidth=1.5) +
  stat_function(fun=df, geom='line', args=c(df1 = 10, df2=100), color = accent3, linewidth=1.5) +
  annotate('text', label = 'df1 = 2, df2 = 10', color = baseColor, x = 4, y = .75, size = 5) +
  annotate('text', label = 'df1 = 5, df2 = 10', color = accent1, x = 4, y = .6, size = 5) +
  annotate('text', label = 'df1 = 5, df2 = 100', color = accent2, x = 4, y = .45, size = 5) +
  annotate('text', label = 'df1 = 10, df2 = 100', color = accent3, x = 4, y = .3, size = 5) +
  labs(x = 'F-statistic') +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 16, face = 'bold'),
        axis.text.x = element_text(size = 14))

```
]

---
class: center, inverse, middle

## Questions?

---
exclude: true

## Wooclap questions slide!

