---
title: "Week 5 Lab: t-tests"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
    css: https://mtruelovehill.github.io/PRM/Labs/css/style.css
runtime: shiny_prerendered
---


```{r setup, include=FALSE}
library(learnr)

pacman::p_load('tidyverse', 'kableExtra')

baseColor <- '#4CA384'
accent1 <- '#9AD079'
accent2 <- '#C4C6C7'
accent3 <- '#19424C'
```

## Intro to Today's Lab

During today's lab, you'll apply the concepts discussed during this week's lecture. Each lab consists of a range of tasks, with corresponding questions you can answer. Please note that the questions are not required and not marked, although they do provide a helpful source of formative feedback that will help you gauge your understanding. 

In this week's lab, you'll be working with data simulated based on [this paper](https://onlinelibrary.wiley.com/doi/10.1111/infa.12238). In this study, researchers tested the effect of infant transport modality on their total number of vocalisations during transport. Specifically, they compared infant vocalisations when infants were being pushed in buggies or being carried in backpacks. 

### Learning Objectives
At the end of this lab, you will be able to:

1. Identify hypotheses which may be tested using $t$-tests
2. Perform a power analysis for an independent-samples $t$-test
3. Check assumptions for an independent-samples $t$-test
4. Use SPSS to perform an independent-samples $t$-test
5. Interpret results from an independent-samples $t$-test

If you complete the bonus material, you'll also be able to:

1. Present your results as you would in an APA-style report
2. Conduct an appropriate power analysis for a paired-samples $t$-test.
3. Check assumptions for paired-samples $t$-tests
4. Use SPSS to perform a paired-samples $t$-test
5. Interpret results from a paired-samples $t$-test


## Study Overview 

Researchers wanted to test whether the amount of time an infant spent vocalising differed depending on whether parents used a buggy or a backpack to transport their infant. They recruited 36 participants and split them into a backpack group and a buggy group. They then sent participants on a 15-minute walk with their infant and recorded the amount of time infants spent vocalising over the course of the walk.

**You can download the dataset for this study [here.](https://mtruelovehill.github.io/PRM/Labs/ttestLabData.sav)** This dataset contains the following variables:

```{r, echo = F}
dat <- read.csv('https://mtruelovehill.github.io/PRM/Labs/ttestLabData.csv')
datInfo <- data.frame(VariableName=colnames(dat),
                      Description=c('Levels: 0 = Male, 1 = Female', 'Infant age in weeks',
                                    'Transport Modality; Levels: 0 = Buggy; 1 = Backpack',
                                    'Time infant spent vocalising (in seconds)'))
 
datInfo %>%
  kbl(col.names=c('Variable Name', 'Description')) %>%
  kable_styling(full_width = F) %>%
  row_spec(0, bold = T, color=baseColor, font_size = 18, align='l') %>%
  column_spec(1, bold = T, width = '4.5cm')
```

<br>

### Your Tasks

<div class="nobullet">
+ [ ] $\ $ Identify the independent and dependent variables in this experiment

+ [ ] $\ $ State both the null and alternative hypothesis

+ [ ] $\ $ Specify your hypothesis using statistical notation
</div>

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for a hint </span></summary>

If you need guidance on how to specify your hypothesis using statistical notation, [see the lecture slides](https://mtruelovehill.github.io/PRM/Lectures/Week04_ttests_lecture.html)

</details>
</div>
</br>

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for the solution </span></summary>

<br>

<b> Variables: </b>

Independent Variable: Transportation Modality

Dependent Variable: Amount of Infant Vocalisation (in seconds)

<br>

<b>Hypotheses:</b>

Null Hypothesis: There is no difference in infant vocalisation time between buggy users and backpack users.

Alternative Hypothesis: There is a difference in infant vocalisation time between buggy users and backpack users.

<br>

<b>Hypotheses in Statistical Notation:</b>

$H_0: Vocalisation_{buggy} = Vocalisation_{backpack}$

$H_1: Vocalisation_{buggy} \neq Vocalisation_{backpack}$

</details>
</div>
</br>

## Power Analyses

After deciding on your hypotheses but before gathering data, you should run a power analysis to determine the sample necessary to capture your effect of interest.

Recall the effect size measure for $t$-tests, $d$:

| Strength | Absolute Magnitude of $d$ |
|:--------:|:-------------------------:|
| Weak     | $\leq$ .20                |
| Moderate | $\approx$ .50             |
| Strong   | $\geq$ .8                 |

### Your Task

<div class="nobullet">
+ [ ] $\ $ Run a power analysis using $\alpha$ = .05 and power = .8 to determine the sample size necessary to detect a moderate effect size. Assume you will have an equal number of participants in each group.
</div>

Click [here to use WebPower to run your analysis](https://webpower.psychstat.org/wiki/models/index).

```{r powerQuiz, echo = F}

quiz(caption = 'Check Your Results',
     question_numeric('How many total participants do you need for this analysis, given the above parameters?',
                      answer(128, correct = T),
                      message = 'You need 64 participants in each group to have 80% power to detect a moderate effect with alpha = .05. This would be a total of 128 participants.'))
```

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for a hint </span></summary>

This power analysis uses/outputs the number of participants in each group, rather than the total number of participants. 

</details>
</div>
</br>

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for the solution </span></summary>

Navigate to the WebPower site. For $t$-tests, you'll be using one of these options, depending on whether your sample within each group will be equal or not.

```{r, echo = F, fig.align='center', out.width='50%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_powerOptions.png')
```


<span style = "font-weight: bold; font-size: 14pt"> Study 1 </span>

Because you're assuming an equal sample size within each group, you will click the first option: "Power of t-test." You'll leave the Sample Size option blank, as that's the value you want to calculate. You'll fill in the other options as follows:

```{r, echo = F, fig.align='center', out.width='50%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_powerParams.png')
```

Because you'll be running an independent-samples $t$-test, the 'Type of Test' option will be 'Two sample.' 

```{r, echo = F, fig.align='center', out.width='50%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_powerOutput.png')
```

Note that the sample size refers to the sample PER GROUP, not the total sample. In other words, to achieve 80% power to detect a moderate effect size with an alpha = .05, you would need 64 participants per group, or 128 total participants.

To report these results, you could say something like

"An a priori power analysis indicated that 128 participants (64 per group) was necessary to achieve 80% power to detect a moderate effect size ($d$ = .50) with $\alpha$ = .05 using an independent-samples $t$-test."

</details>
</div>
</br>


## Descriptive Data

Before running any analyses, you should first check your data. In many cases, some kind of cleaning or data wrangling will be necessary. For instance, are there any missing values? Do you have any unexpected values or extreme outliers? Do you need to create a variable from the existing data (e.g., a summary metric for a cognitive task)? These things should be dealt with before conducting the analyses.

Additionally, you'll need to compute descriptive data. You'll do this for both your main variables of interest and your sample's demographic data, as this must be included in the Sample portion of your Methods section. 

### Your Tasks

<div class="nobullet">
+ [ ] $\ $ Open 'ttestLabData.sav' in SPSS

+ [ ] $\ $ Check whether all variables imported into SPSS as the correct measurement type

+ [ ] $\ $ Add a key to `infantGender` and `Transport` variables so it is clear what 0 and 1 represent.

+ [ ] $\ $ Check the descriptive statistics of your data

</div>


```{r cyrDD, echo = FALSE}
quiz(caption = 'Check Your Results',
     question_numeric("How many female infants participated?",
              answer(59, correct = T),
              message = '59 female infants participated in the study.'),
     question_numeric('What is the minimum amount of time infants spent vocalising? Please round your answer to 2 decimal places.',
                      answer(8.08, correct = T),
                      message = 'The minimum number of infant vocalisations is 8.08.'))
```

<br>

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for a hint </span></summary>

You can check the variables and add a key to `infantGender` and `Transport` under the *Variable View* tab. To calculate descriptive statistics, navigate to *Analyze > Descriptive Statistics > Frequencies*. You'll need to check the mean, standard deviation, minimum, and maximum for continuous data and create frequency tables for categorical data.

</details>
</div>
</br>

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for the solution </span></summary>

When you check the data under *Variable View*, you'll see that all variables were imported as the proper measurement. Use the 'Values' column to add labels to the `infantGender` and `Transport` variables: 

```{r, echo=F, fig.align='center', out.width='50%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_addLabels.png')
```


Next, produce frequency tables and descriptive statistics by navigating to *Analyze > Descriptive Statistics > Frequencies*. Add the 2 categorical variables, `infantGender` and `Transport`, to the *Variable(s)* box and make sure 'Display Frequency Tables' is checked, then click 'OK'. If this is done this properly (and you've correctly added variable keys), you'll see the following output:

```{r, echo=F, fig.align='center', out.width='50%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_frequencies.png')
```

Here, you can see the frequencies of participants in each category. You might note that there were more male infants than females. You can see that there are equal participants in the 'Buggy' and 'Backpack' groups, as expected.

After checking the categorical variables, you can check the continuous data. Open the *Frequencies* box once again and replace the categorical variables with the 2 continuous variables, `infantAge` and `vocalisationTime`. Uncheck 'Display Frequency Tables' and click the 'Statistics' box. Select 'Mean', 'Std. deviation', 'Maximum' and 'Minimum', then click 'Continue'. Click 'OK'. You should get the following table:

```{r, echo=F, fig.align='center', out.width = '50%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_descriptives.png')
```

Have a look at the values here. There is no missing data, and the values seem reasonable, so you can move forward to the next step.


</details>
</div>
</br>


## Checking Assumptions

The assumptions of an independent-samples $t$ test are:

(1) The dependent variable (`vocalisationTime`) must be normally distributed within each group

(2) Observations must be independent of each other

(3) The two groups (*Buggy* and *Backpack*) must exhibit approximately equal variance (homogeneity) in the dependent variable (`vocalisationTime`)


### Your Tasks

<div class="nobullet">
+ [ ] $\ $ Check whether your data meet the assumption of normality

+ [ ] $\ $ Check whether your data meet the assumption of independence

+ [ ] $\ $ Check whether your data meet the assumption of homogeneity

</div>

<br>

```{r cyrAssumptions, echo = FALSE}
quiz(caption = 'Check Your Results',
     question("At least one of the assumptions is violated.",
              answer("True"),
              answer("False", correct = T),
              message = "The normality plots show no major issues in normality, and Levene's test is not significant, indicating that homogeneity of variance can be assumed."))
```


<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for a hint </span></summary>
To check normality, you can use histograms and Q-Q plots. You'll need to do this for each level of `Transport` separately. Navigate to *Analyze>DescriptiveStatistics>Explore* to do this. 

To check independence, you'll need to consider the design of the study. To check homogeneity of variance, you can check results from Levene's test.

Have a look at the [lecture slides](https://mtruelovehill.github.io/PRM/Lectures/Week04_ttests_lecture.html) if you're lost. [This article](https://link.springer.com/article/10.3758/s13428-023-02072-x) to provide helpful guidance on why we check assumptions, and why certain assumption checking methods are more strongly recommended than others.

</details>
</div>
</br>


<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for the solution </span></summary>

<br>

<span style = "font-weight: bold; font-size: 14pt"> Checking Normality </span>

Normality can be assessed in multiple ways. Visual assessment is recommended, as the statistical tests can be overly sensitive, particularly with larger sample sizes. 

To check the histograms and Q-Q plots of the dependent variable separated by Group, click *Analyze > Descriptive Statistics > Explore* and add your dependent variable, `vocalisationTime`,  to the 'Dependent List' box. Add your independent variable, `Transport`, to the Factor List box. At the bottom, change the 'Display' setting from 'Both' to 'Plots'. Click 'Plots', deselect 'Stem-and-Leaf' and select 'Histograms' instead. Tick the box that says 'Normality Plots with Tests'. Click 'Continue', then 'OK'.

```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_buggyHist.png')

knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_backpackHist.png')
```

`vocalisationTime` appears to be generally normal within each `Transport` group. There is no evidence of a significant normality violation. 


```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_buggyQQ.png')

knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_backpackQQ.png')
```

Inspecting the Q-Q plots, you'll note that the points go very slightly off the line in the tails, but not in a concerning way. On the whole, these results indicate that the data have not violated the assumption of normality.

<span style = "font-weight: bold; font-size: 14pt"> Independence </span>

Assessing independence requires an understanding of the conditions under which the data were collected. The study design (between-participants) increases the likelihood that the observations are independent of each other. In this example, we'll consider this assumption met.

<span style = "font-weight: bold; font-size: 14pt"> Homogeneity of Variance </span>

Although this can be tested using Levene's test, this option has the same limitations as statistical tests of normality. Instead, a Welch's $t$-test can be used by default. This test accounts for heterogeity of variance, and so can be run even when the assumption is violated.

</details>
</div>
</br>

## Inferential Analysis

An independent-samples $t$-test produces a statistic that quantifies the degree of difference between two independent means. As you are comparing two independent means, you'll use results from an independent-samples $t$-tests to provide statistical support for your hypothesis. Recall that you're testing the following hypothesis:

$$H_1: Vocalisation_{buggy} \neq Vocalisation_{backpack}$$


### Your Tasks

<div class="nobullet">
+ [ ] $\ $ Conduct an independent-samples $t$-test and interpret the results with $\alpha$ = .05.

+ [ ] $\ $ Compute the effect sizes and confidence intervals associated with your analysis

</div>

```{r cyrIndT, echo = FALSE}
quiz(caption = 'Check Your Results',
     question_numeric("What is the t-statistic associated with vocalisation time? Please round your answer to two decimal places.",
              answer(-3.79, correct = T),
              answer(3.79, correct = T),
              message = 'The t-statistic associated with this test is -3.79 (or 3.79, depending on which order you entered the levels of the independent variable.'),
question("Given an alpha = .05, the difference in vocalisation time between buggy users and backpack users is significant .",
              answer('True', correct = T),
              answer('False'),
              message = 'The p-value for this test is < .001. This means that if the null hypothesis were true, the likelihood that we would see this big of a difference in vocalisation time between buggy and backpack users is less than .1%. This provides strong evidence against the null hypothesis. Practically speaking, as our p-value is less than our alpha threshold is .05, we will reject the null hypothesis and claim that there is a significant difference in infant vocalisation between buggy and backpack users.'))
```

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for a hint </span></summary>

You can run the test by clicking *Analyze > Compare Means and Proportions > Independent-Samples T test*.

</details>
</div>
</br>

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for the solution </span></summary>

Click *Analyze > Compare Means and Proportions > Independent-Samples T test*. Move your dependent variable, `vocalisationTime` into the 'Test Variable(s)' box and your independent variable, `Transport`, into the 'Grouping Variable' box. Click 'Define Groups' and enter the names of your two groups (*Buggy* and *Backpack*) exactly as they are provided in the spreadsheet. In the main box, make sure 'Estimate effect sizes' is checked, then click 'OK' to run the test.

The first bit of output will provide the descriptive statistics separated by `Transport` groups. This is useful information to include in your final report, so take note.

```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_groupDescs.png')
```

<br>

The second bit of output provides the results of the $t$-test. The first portion provides the results from Levene's test. It can be ignored. If you were performing a traditional $t$-test, the first row would be interpreted. However, as you will be using the Welch's $t$-test by default, you should look at the results in the second row, which is labeled 'Equal variances not assumed'. This row contains the results from Welch's $t$-test.

```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_results.png')
```

<br>

Recall that you tested a nondirectional hypothesis (*There will be **a difference** in infant vocalisation between backpack and buggy users* rather than *Backpack users will vocalise **more** than buggy users*). Because of this, you'll evaluate significance using the $p$-value in the 'Two-sided p' column. Had you tested a directional hypothesis, you would check the $p$-value in the 'one-sided p' column.

The results from the t-test suggest that infant vocalisation was significantly different between buggy and backpack users, as the $p$-value of < .001 is less than the $\alpha$ threshold of .05. The confidence intervals for the variables further support this; the 95% CI associated with `vocalisationTime` does not contain the null value of 0.

<br>

To check the effect size, look under the 'Point Estimate' column for Cohen's $d$:

```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_effectSize.png')
```


Recall the interpretation standards for Cohen's $d$:

| Strength | Absolute Magnitude of $d$ |
|:--------:|:-------------------------:|
| Weak     | $\leq$ .20                |
| Moderate | $\approx$ .50             |
| Strong   | $\geq$ .8                 |

Based on these standards, there is a moderate effect of transport modality on infant vocalisation in the current sample. 

</details>
</div>
</br>

## Test Your Understanding

```{r tyo, echo = FALSE}
quiz(caption = '',
     question('Which of the following hypotheses could be tested using a t-test? Please select all that apply.',
              answer("This year's average rice crop produced significantly higher yields than last year's.", correct = T),
              answer('Therapies A, B, and C significantly differ from each other in effectiveness.'),
              answer('A 30-minute weightlifting routine burns more calories than a 30-minute cardio routine.', correct = T),
              answer('There is an association between brain volume and processing speed.'),
              random_answer_order = T,
              message = 'The therapy research question is better suited to an ANOVA or a regression, as it is comparing 3 means. A t-test can only compare two at a time. The brain volume research question asks about an association between two continuous variables. A t-test requires a categorical independent variable. This question is better answered with a correlation or regression.'),
     question('You have developed an intervention and want to test its effectiveness. You recruit a sample of participants and measure their symptom severity both before and after the intervention. You measure patient symptom severity on a continuous scale. You would like to compare the two symptom severity scores. Which of the following tests is most appropriate?',
              answer('One-sample t-test'),
              answer('Independent samples t-test'),
              answer('Paired-samples t-test', correct = T),
              message = "Because you have a pre- and post-intervention measurement from each participant, the two scores are considered to be paired. An individual's score on the post-test will not be independent of their scores on the pre-test. A paired-samples t-test will account for this lack of independence between the two groups of scores."),
     question("Which of the following could be used to assess normality? Please select all that apply.",
              answer('Histograms', correct = T),
              answer('Q-Q Plots', correct = T),
              answer('Shapiro-Wilk Test', correct = T),
              answer('Skewness & Kurtosis values', correct = T),
              message = 'All of the above could be used to assess normality. However, statistical tests (e.g., the Shapiro-Wilk test) are not recommended.'),
     question('A researcher makes a nondirectional hypothesis and runs an independent t-test in SPSS. Under which column will they find the appropriate significance value?',
              answer('One-sided p'),
              answer('Two-sided p', correct = T),
              answer('Either of these options will provide an appropriate significance value.'),
              message = 'When evaluating a nondirectional hypothesis, you must run a two-tailed test, as you are testing for an extreme value in either direction.'),
     question('A researcher runs an independent test in SPSS and gets the following 95% confidence interval of the difference: [-.28, .83]. Which of the following is true, assuming alpha = .05?',
              answer('The results are significant.'),
              answer('The results are not significant', correct = T),
              answer("Significance can't be evaluated using this information"),
              message = "The null hypothesis of an independent-samples t-test is that the difference between the means of each group is 0. If the confidence interval contains 0, it means that 0 is a plausible value for the true difference between groups. Therefore, you don't have enough evidence to reject the null hypothesis that the true difference between groups is 0."),
     question_numeric('You are running a secondary analysis with 134 participants (85 in group 1; 49 in group 2). You make a nondirectional hypothesis and set alpha = .05. What is the maximum effect size you can detect with a power of 80%? Please round your answer to two decimal places.',
                      answer(.51, correct = T),
                      message = 'The maximum effect size you could detect in this instance is .51. In this example, you were working with an unbalanced sample, so you needed to run a power analysis that accounts for this. A power analysis that assumes equal group sizes would have given you a slightly different answer (.49). You would have also received an inaccurate result if you used the total sample size rather than sample per group (.34)'),
     question_numeric('How many participants do you need per group to detect a strong effect (d = .8) with an independent-samples t-test, a nondirectional hypothesis, power = .8, and alpha = .001?',
                      answer(57, correct = T),
                      message = 'You will need 57 participants per group to detect this effect. You will have needed to round up, as you cannot have .09 participants.'),
     question('You run a power analysis for a one-tailed (directional) test. Holding power, effect size, and alpha constant, how do the sample size requirements change compared to a two-tailed (nondirectional) test?',
              answer('The sample size requirements increase for a one-tailed test'),
              answer('The sample size requirements decrease for a one-tailed test', correct = T),
              answer('The sample size requirements are identical for both one- and two-tailed tests'),
              message='When using an alpha = .05, we consider values in the most extreme 5% of the distribution to be significant. When running a two-tailed test, this 5% is split in both directions, so the 2.5% highest AND 2.5% lowest values are considered significant. In a one-tailed test, only the extreme results in one direction are considered significant, so all 5% is grouped in a single area of the distribution. This naturally increases the power to detect an effect as the critical threshold in that direction is closer to the mean. Because of this, a smaller sample size in a one-tailed analysis can produce the same power level as a larger sample size in a two-tailed analysis.'))

```

## Bonus Material: Intepret & Report

Now that you've completed the analyses, write a mini report describing your findings. In this report, please:

+ Give a brief description of your sample as you would in a methods section. 

+ Present your results as you would in a results section.

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for a hint </span></summary>

There are many ways you could write this up, but you should at least include the following information:

+ alpha level
+ number of participants (n)
+ participant demographics (mean age, age sd, and age range of sample; gender distribution of sample)
+ results from assumptions checks
+ descriptive data for each group (M and SD)
+ the type of test used (independent or paired-samples?)
+ independent and dependent variables tested
+ $t$-statistics
+ degrees of freedom
+ p-values
+ confidence intervals
+ effect sizes

The proper style of reporting the results from a $t$-test looks like this:

$t$(##) = #.##, $p$ = .###, 95% CI = [#.##, #.##], $d$ = #.##.

Note that the numbers inside the curly brackets refer to the degrees of freedom. Please refer to the [lecture slides](https://mtruelovehill.github.io/PRM/Lectures/Week04_ttests_lecture.html) for a specific example.


</details>
</div>
</br>

## Bonus Material: Paired-Samples $t$-test
After running the first experiment, the researchers wanted to further support their findings. They ran a second experiment using a within-subjects design. They recruited 40 participants and sent them out on 2 separate walks over the course of two weeks, once using a backpack and once a buggy. In this experiment, they recorded the time infants spent vocalising from the same participants across each condition.

**Please download the dataset from the second experiment [here.](https://mtruelovehill.github.io/PRM/Labs/ttestBonusData.sav)** It contains the following variables:

```{r, echo = F}
dat2 <- read.csv('https://mtruelovehill.github.io/PRM/Labs/ttestBonusData.csv')
dat2Info <- data.frame(VariableName=colnames(dat2),
                      Description=c('Infant age in weeks',
                                    'Levels: 0 = Male, 1 = Female', 
                                    'Time infants spent vocalising while in buggy',
                                    'Time infants spent vocalising while in backpack'))
 
dat2Info %>%
  kbl(col.names=c('Variable Name', 'Description')) %>%
  kable_styling(full_width = F) %>%
  row_spec(0, bold = T, color=baseColor, font_size = 18, align='l') %>%
  column_spec(1, bold = T, width = '4.5cm')
```

### Your Tasks

<div class="nobullet">
+ [ ] $\ $ Task 1: State your hypotheses and identify your independent and dependent variables

+ [ ] $\ $ Task 2: Conduct the appropriate power analysis, assuming an $\alpha$ = .05, power = .8, and a moderate effect size.

+ [ ] $\ $ Task 3: Check Experiment 2 data
  
+ [ ] $\ $ Task 4: Check Experiment 2 assumptions
  
+ [ ] $\ $ Task 5: Run a paired-samples $t$-test to test your hypothesis and check the effect size and 95% confidence interval

+ [ ] $\ $ Task 6: Report your results using APA style
</div>


<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for a hint </span></summary>
<span style = "font-weight: bold; font-size: 14pt"> Task 1 </span>

Have a look at the [lecture slides](https://mtruelovehill.github.io/PRM/Lectures/Week04_ttests_lecture.html) if you need guidance here.

<span style = "font-weight: bold; font-size: 14pt"> Task 2 </span>

You should change the 'Type of test' option so that it reflects your analysis.

<span style = "font-weight: bold; font-size: 14pt"> Task 3 </span>

You can follow the steps from [Descriptive Data]

<span style = "font-weight: bold; font-size: 14pt"> Task 4 </span>

You'll need to make a new variable to check the assumption of normality, as you need to check the normality of the difference between your paired variables. To do this, use *Transform > Compute Variable* and create a new variable that is the difference between the values in the `buggyVocal` column and the `backpackVocal` column. Once you have this difference variable, follow the steps for normality testing from [Checking Assumptions].

<span style = "font-weight: bold; font-size: 14pt"> Task 5 </span>

To perform a paired-samples $t$-test, navigate to *Analyze > Compare Means and Proportions > Paired Samples T-Test*.

<span style = "font-weight: bold; font-size: 14pt"> Task 6 </span>

See the hint from [Bonus Material: Intepret & Report].

</details>
</div>
</br>

<div class="container">
<details><summary><span style = "font-weight: bold; font-size: 16pt"> Click here for the solution </span></summary>

<span style = "font-weight: bold; font-size: 14pt"> Task 1 </span>

<b> Variables </b>

Independent Variable: Transportation Modality

Dependent Variable: Infant Vocalisation


<b>Hypotheses:</b>
Null hypothesis: There is no difference in the time infants spend vocalising when they are riding in a buggy compared to when they are riding in a backpack.

$H_0: Vocalisation_{buggy}-Vocalisation_{backpack} = 0$

Alternative hypothesis: There is a difference in the time infants spend vocalising when they are riding in a buggy compared to when they are riding in a backpack.

$H_1: Vocalisation_{buggy}-Vocalisation_{backpack} \neq 0$

<br>
<span style = "font-weight: bold; font-size: 14pt"> Task 2 </span>

In the case of a paired-samples analysis, you will expect an equal sample size within each group. You'll need to update 'Type of Test' to 'Paired.' If you entered everything properly, you'll get the following output:

```{r, echo = F, fig.align='center', out.width='50%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_bonusPower.png')
```

To detect an effect of $d$ = .5 with 80% power, given $\alpha$ = .05, you need 34 participants.

To report the results of this power analysis, you could use the following statement:

'An a priori power analysis indicated that a paired-samples $t$-test with 34 participants would provide 80% power to detect an effect size of $d$ = 0.5 with $\alpha$ = .05.'

<br>

<span style = "font-weight: bold; font-size: 14pt"> Task 2 </span>

You can check the frequency of participants in each level of the categorical `Gender` variable by clicking *Analyze>Descriptive Statistics>Frequencies*, moving `infantGender` into the 'Variable(s)' box, then clicking 'Ok'. In this case, you'll note that you have slightly more female infants than male infants.

To check the descriptives of the continuous variables `infantAge`, `buggyVocal` and `backpackVocal`, click *Analyze>Descriptive Statistics>Frequencies*, remove `infantGender` from the Variable(s) box and add the three continuous variables instead. Make sure to untick the 'Display Frequency Tables' box. Click 'Statistics' and then click 'Mean', 'Std. Deviation', 'Minimum', and 'Maximum'. Click 'Continue' and then 'OK'. 

<br>
<span style = "font-weight: bold; font-size: 14pt"> Task 3 </span>

Because we have to check the normality of the difference scores rather than the raw variables, we will need to compute a difference score. To do this, navigate to *Transform > Compute Variable*. Name your new variable in the 'Target Variable' box. Next, move `buggyVocal` to the 'Numeric Expression' box, add a minus sign, then add `backpackVocal.` Click 'OK'. Notice in *Data View* that you now have a new variable that reflects the difference between your paired variables.

```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_bonusCompute.png')
```

Perform the normality tests from [Checking Assumptions] with this new variable.

```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/week4_bonusQQ.png')
```

```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_bonusHist.png')
```

The difference variable looks to be normally distributed, so we will assume normality.

<br>
<span style = "font-weight: bold; font-size: 14pt"> Task 4 </span>

Navigate to *Analyze > Compare Means and Proportions > Paired Samples T-Test*. Add either `buggyVocal` or `backpackVocal` into the Variable1 space and the other into the Variable2 space and click 'OK'. Note that it doesn't matter which goes where. It won't change the values of your results, but it will determine whether your $t$-statistic and effect size is positive or negative.

As before, take note of the descriptive statistics for each group, as you'll need this for reporting purposes. 


The results indicate that the difference in time that infants spent vocalising when in a buggy versus a backpack was significant ($p$ = .013). This is further confirmed by the confidence interval, which doesn't contain the null value of 0. The output also provides the average difference score:

```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_bonusResults.png')
```

Cohen's $d$ indicates there is a moderate effect of transportation modality on time infants spend vocalising:

```{r, echo = F, fig.align= 'center', out.width='75%'}
knitr::include_graphics('https://mtruelovehill.github.io/PRM/Labs/images/ttests_bonusES.png')
```

</details>
</div>
</br>
