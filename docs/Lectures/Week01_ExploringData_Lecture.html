<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title> Exploring Your Data </title>
    <meta charset="utf-8" />
    <meta name="author" content="Monica Truelove-Hill" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# <b> Exploring Your Data </b>
]
.subtitle[
## Psychological Research Methods:<br>Data Management &amp; Analysis<br><br>
]
.author[
### Monica Truelove-Hill
]
.institute[
### Department of Clinical Psychology<br>The University of Edinburgh
]

---








## Why????

+ Psychology is a science....

--

+ with a lot of uncertainty

--

+ To answer our research questions, we rely on empirical evidence 

+ We take measurements that allow us to make systematic observations of our construct of interest, then use these observations to draw conclusions

+ In other words, we gather data and look for consistent patterns within the data that support (or refute) our ideas

+ But how do we decide what is *consistent enough*?

---

## Research process

&lt;img src="images/ResearchProcess.png" width="2411" /&gt;

---
exclude: true
## The truth is out there.

---
## From sample to population

+ In statistics, we often refer to samples and populations
  
  + **Population:** The entire group about whom you're making inferences
  
  + **Sample:** The subset of the population from whom you will collect data to make these inferences
  
+ We typically use **sample statistics**, or **point-estimates** to make inferences about **population parameters**

---
## Hypotheses

+ **Null Hypothesis ( `\(H_0\)` ):** There is no difference or effect, and any experimentally observed difference is due to chance

+ **Alternative Hypothesis ( `\(H_1\)` ):** There is a relationship or association between variables

+ The burden of proof is on `\(H_1\)`

  + Assume `\(H_0\)` is accurate until there is sufficient evidence that it is not
  
  + Tests of significance assess strength of the evidence against `\(H_0\)`

---
## Visualising your data: Frequency Distributions

+ Frequency distributions allow you to visualise how often each observation occurs

+ The type of frequency distribution you should use depends on the type of data you have:

--

.pull-left[
.center[**Categorical Data: Bar Plots**]
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-3-1.svg)&lt;!-- --&gt;
]

.pull-right[
.center[**Continuous Data: Histograms**]
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-4-1.svg)&lt;!-- --&gt;
]

---
## Describing your data: Central Tendancy

+ What is the middle-ish point of your data?

+ Can estimate in 3 ways:
  + **Mean**
  + **Median**
  + **Mode**
  
---
## Central Tendancy: Mean

.pull-left[


**The mathematical notation:**

`$$\bar{x} = \frac{\displaystyle\sum_{i=1}^{n}x_i}{n}$$`
+ Where:
    + `\(n\)` = total number of values in the data
    + `\(x_i\)` = an individual value in the data
    + `\(\displaystyle\sum_{i=1}^{n}\)` = sum all values between 1 ( `\(i=1\)` ) and `\(n\)`

]

---
count: false

## Central Tendancy: Mean

.pull-left[

**The mathematical notation:**

`$$\bar{x} = \frac{\displaystyle\sum_{i=1}^{n}x_i}{n}$$`
+ Where:
    + `\(n\)` = total number of values in the data
    + `\(x_i\)` = an individual value in the data
    + `\(\displaystyle\sum_{i=1}^{n}\)` = sum all values between 1 ( `\(i=1\)` ) and `\(n\)`

    
**In basic language:** 
 
 + The mathematical average; sum all values and divide by the total number of values
]

--

.pull-right.center[

`\(x = \{10, 2, 5, 3, 2, 0, 12\}\)`

`\(\bar{x} = \frac{\sum(10, 2, 5, 3, 2, 0, 12)}{7}\)` 


`\(\bar{x} = 4.86\)` 


&lt;img src="images/SPSSmean.PNG" width="45%" /&gt;

]

---
## Central Tendancy: Mean

+ Can be used with _continuous/numeric_ data (i.e. interval and ratio data)

+ Shouldn't be used with nominal data, and it's best not used with ordinal data, even though they may be coded as numeric values


--


+ Say you have the following scale:

.pull-left[


| Scale  | Rate your understanding of the lecture     |
|--------|--------------------------------------------|
|    1   | I'm completely lost.                       |
|    2   | I'm a bit confused.                        |
|    3   | I understand about half of it.             |
|    4   | It's starting to come together.            |
|    5   | Everything is perfectly clear.             |

]

.pull-right[

&gt; **Test your understanding:** What does a mean of 3.2 actually mean, in the context of this scale?

]

---
count: false

## Central Tendancy: Mean

+ Can be used with _continuous/numeric_ data (i.e. interval and ratio data)

+ Shouldn't be used with nominal data, and it's best not used with ordinal data, even though they may be coded as numeric values

+ Say you have the following scale:

.pull-left[


| Scale  | Rate your understanding of the lecture     |
|--------|--------------------------------------------|
|    1   | I'm completely lost.                       |
|    2   | I'm a bit confused.                        |
|    3   | I understand about half of it.             |
|    4   | It's starting to come together.            |
|    5   | Everything is perfectly clear.             |

]

.pull-right[

&gt; **Test your understanding:** What does a mean of 3.2 actually mean, in the context of this scale?

&gt; Is someone who is a bit confused twice as confused as someone for whom it's starting to come together?

]
---
## Central Tendancy: Median

+ The value in the exact center of a range

+ Can be used with ordinal, ratio, or interval data

.pull-left[
.center[
**If there are an odd number of values:**

`\(x = \{10, 2, 5, 3, 2, 0, 12\}\)`

`\(0, 2, 2, \color{#4CA384}{3}, 5, 10, 12\)`

**Median `\(x\)` = 3**

]
]


.pull-right[
.center[
**If there are an even number of values:**

`\(y = \{3, 7, 1, 20, 14, 25\}\)`


`\(1, 3, \color{#4CA384}{7, 14,} 20, 25\)`


`\(\frac{7+14}{2} = 10.5\)`


**Median `\(y\)` = 10.5**
]



]


---
## Central Tendancy: Mode

.pull-left[
+ The value that appears most frequently in a range

+ Can be used with all types of data, although may be less descriptive of continuous data depending on the precision of the measurement

+ Data may be bimodal or multimodal

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-6-1.svg)&lt;!-- --&gt;

]

--

.pull-right.center[

`\(x = \{10, \color{#4CA384}{2}, 5, 3, \color{#4CA384}{2}, 0, 12\}\)`

&lt;img src="images/SPSSmode.PNG" width="85%" /&gt;

]


---

####  How useful are the measures of central tendency in each of the following situations?

.pull-left.center[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-8-1.svg)&lt;!-- --&gt;

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-9-1.svg)&lt;!-- --&gt;
]

.pull-right.center[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-10-1.svg)&lt;!-- --&gt;

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-11-1.svg)&lt;!-- --&gt;

]


---
## Limitations of Central Tendency

+ In isolation, central tendency doesn't sufficiently describe the data

.pull-left[

| Participant |  Test Score |
|:-----------:|:-----------:|
| 1           |    6        |
| 2           |    5        |
| 3           |    6        |
| 4           |    5        |
| 5           |    5        |
| Total       |    27       |

.center[
**Mean = 5.4**
]

]

.pull-right[

| Participant |  Test Score |
|:-----------:|:-----------:|
| 1           |    2        |
| 2           |    2        |
| 3           |    10       |
| 4           |    10       |
| 5           |    3        |
| Total       |    27       |

.center[
**Mean = 5.4**
]

]

---
## Variation in Scores

.pull-left[
+ Helps us to understand how well the mean describes our data

+ Can estimate this using:

  + Maxima &amp; Minima
  
  + Range
  
  + Interquartile Range

  + Variance
  
  + Standard Deviation
]


--


.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-12-1.svg)&lt;!-- --&gt;
]


---
## Variation in Scores

.pull-left[
+ Helps us to understand how well the mean describes our data

+ Can estimate this using:

  + **Maxima &amp; Minima**
  
  + Range
  
  + Interquartile Range

  + Variance
  
  + Standard Deviation
]


.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-13-1.svg)&lt;!-- --&gt;
]

---
## Variation in Scores

.pull-left[
+ Helps us to understand how well the mean describes our data

+ Can estimate this using:

  + Maxima &amp; Minima
  
  + **Range**
  
  + Interquartile Range

  + Variance
  
  + Standard Deviation
]


.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-14-1.svg)&lt;!-- --&gt;
]

---
## Variation in Scores - Interquartile Range

.pull-left[
+ Interquartile Range (IQR) tells you about the spread in the middle range of your data

+ It allows you to get a sense of variation in your data, excluding the most extreme values

+ This metric depends on the order of the values in the data, so note that the plot has been reordered based on Age. 

+ **NOTE:** The IQR is a key component of a boxplot, which we will return to later in the course
]


.pull-right[


![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-15-1.svg)&lt;!-- --&gt;
]

---
## Variation in Scores - Interquartile Range

.pull-left[
+ First, calculate the median of your data

  + In our case, the median is the average of 31 and 33
  
  + This becomes our 2nd Quartile (Q2)

]


.pull-right[

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-16-1.svg)&lt;!-- --&gt;
]

---
count: false

## Variation in Scores - Interquartile Range

.pull-left[
+ First, calculate the median of your data

  + In our case, the median is the average of 31 and 33
  
  + This becomes our 2nd Quartile (Q2)

+ Q4 = the maximum value in your data

]


.pull-right[


![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-17-1.svg)&lt;!-- --&gt;
]

---
## Variation in Scores - Interquartile Range


.pull-left[
+ Next, calculate the remaining quartiles of your data

  + There are several ways to do this, and all will give you slightly different outcomes
  
  + This method uses *Tukey's Hinges*:
     
     + With an **even** number of observations:
        
        + Split the data in half at Q2.
        
        + Identify the median of all values below Q2. This is Q1.
        
        + The median of all values above Q2 is Q3.
]

.pull-right[

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-18-1.svg)&lt;!-- --&gt;


]   

---
## Variation in Scores - Interquartile Range


.pull-left[
+ Next, calculate the remaining quartiles of your data

  + There are several ways to do this, and all will give you slightly different outcomes
  
  + This method uses *Tukey's Hinges*:
     
     + With an **odd** number of observations:
        
        + Split the data in half at Q2.
        
        + Q1 is the median of all values below Q2, including Q2.
        
        + Q3 is the median of all values above Q2, including Q2.
]

.pull-right[

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-19-1.svg)&lt;!-- --&gt;


]   
---
## Variation in Scores - Interquartile Range


.pull-left[
+ Finally, calculate the IQR
      
     + `\(IQR=Q3-Q1\)`
     
     + `\(34.5 - 26.5 = 8\)`
     

&lt;img src="images/TukeysHinges.png" width="1152" /&gt;


]

.pull-right[

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-21-1.svg)&lt;!-- --&gt;


]   

---
## Variation in Scores - Variance

.pull-left[

`$$s^2 = \frac{\sum(x_i-\bar{x})^2}{n-1}$$`
]

.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-22-1.svg)&lt;!-- --&gt;

]


---
## Variation in Scores - Variance

.pull-left[

`$$s^2 = \frac{\sum(\color{#4CA384}{x_i}-\bar{x})^2}{n-1}$$`

+ `\(x_i\)` = individual observations of x
]

.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-23-1.svg)&lt;!-- --&gt;

]

---
## Variation in Scores - Variance

.pull-left[
`$$s^2 = \frac{\sum(x_i-\color{#4CA384}{\bar{x}})^2}{n-1}$$`


+ `\(x_i\)` = individual observations of x

+ `\(\bar{x}\)` = mean of variable x

]

.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-24-1.svg)&lt;!-- --&gt;

]

---
## Variation in Scores - Variance

.pull-left[
`$$s^2 = \frac{\sum(\color{#4CA384}{x_i-\bar{x}})^2}{n-1}$$`


+ `\(x_i\)` = individual observations of x

+ `\(\bar{x}\)` = mean of variable x

]

.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-25-1.svg)&lt;!-- --&gt;

]

---
## Variation in Scores - Variance

.pull-left[
`$$s^2 = \frac{\sum(x_i-\bar{x})\color{#4CA384}{^2}}{n-1}$$`


+ `\(x_i\)` = individual observations of x

+ `\(\bar{x}\)` = mean of variable x

&gt; **Test Your Understanding:** Why do we need to square these values before summing them?

]

.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-26-1.svg)&lt;!-- --&gt;

]

---
## Variation in Scores - Variance

.pull-left[
`$$s^2 =\frac{\sum(x_i-\bar{x})^2}{n-1}$$`


+ `\(x_i\)` = individual observations of x

+ `\(\bar{x}\)` = mean of variable x

+ `\(\sum(x_i-\bar{x})^2\)` = sum of squared deviations (AKA the sum of squares)

+ `\(s^2 = \frac{526.22}{12-1} = 47.84\)`

]

.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-27-1.svg)&lt;!-- --&gt;

]

---
## Why n-1?

+ Recall that we are using a sample to make estimates about the overall population

+ In doing so, we are assuming that our sample mean reflects the population mean

+ Adding -1 allows us to make an estimate of the population variance that's less biased by our specific sample.

--

&gt; **Test your understanding:** Is a smaller sample MORE or LESS likely to reflect the overall population?

--

.pull-left[
+ Imagine that we have calculated the sum of squares to be 127
]

.pull-right[

| Sample Size | Variance (n)          | Variance (n - 1)     |
|:-----------:|:---------------------:|:--------------------:|
|    5        |  25.4  | 31.75  |
|    10       |  12.7  | 14.11  |
|    50       |  2.54  | 2.59  |
|    100      |  1.27 | 1.28  |
|    1000     |  0.13| 0.13 |

]


???

Probably a wider spread in the population than what we are accounting for in our small sample

As the sample grows larger, the variance estimated using n or n-1 grows more similar


---
## Variation in Scores - Standard Deviation

.pull-left[
`$$SD =\sqrt\frac{\sum(x_i-\bar{x})^2}{n-1}$$`
+ On average, how far away are individual observations from the mean? 

+ Expressed in the units of the variable of interest

+ `\(SD = \sqrt{47.84} = 6.92\)`

+ On average, participants in our sample are 6.92 years older or younger than the mean of 31.25.

]

--

.pull-right.center[
**Mean = 10, SD = 1**
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-28-1.svg)&lt;!-- --&gt;

**Mean = 10, SD = 10**

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-29-1.svg)&lt;!-- --&gt;

]


---
## Why SD? Why not just variance?

+ To illustrate this, let's look at an example with distance in miles and the corresponding values in kilometers:




.pull-left[

| Miles | Kilometers|
|:-----:|:---------:|
| 4.25 | 6.84       |
| 2.61 | 4.20       |
| 1.13 | 1.82       |
| 5.89 | 9.48       |
| 8.60 | 13.85      |

+ Miles = km/1.61

]

--

.pull-right[

| Statistic         | Miles       | Kilometers |
|:-----------------:|:-----------:|:----------:|
|  `\(Sum\ of\ Squares\)` | 33.73 | 87.49   |
|    `\(s^2\)`          | 8.43 | 21.87   |


]


---
count: false

## Why SD? Why not just variance?

+ To illustrate this, let's look at an example with distance in miles and the corresponding values in kilometers:

.pull-left[

| Miles | Kilometers|
|:-----:|:---------:|
| 4.25 | 6.84       |
| 2.61 | 4.20       |
| 1.13 | 1.82       |
| 5.89 | 9.48       |
| 8.60 | 13.85      |

+ Miles = km/1.61

]

.pull-right[

| Statistic         | Miles       | Kilometers |
|:-----------------:|:-----------:|:----------:|
|  `\(Sum\ of\ Squares\)` | 33.73 | 87.49   |
|    `\(s^2\)`          | 8.43 | 21.87   |

+ `\(21.87/1.6 = 13.67\)`

+ `\(13.67 \neq 8.43\)` 

+ Variance values are **not in the same units as the original data**, so they won't conform to the same rules

+ This also affects interpretability

]


---
## Why SD? Why not just variance?

+ To illustrate this, let's look at an example with distance in miles and the corresponding values in kilometers:

.pull-left[

| Miles | Kilometers|
|:-----:|:---------:|
| 4.25 | 6.84       |
| 2.61 | 4.20       |
| 1.13 | 1.82       |
| 5.89 | 9.48       |
| 8.60 | 13.85      |

+ Miles = km/1.61

]

.pull-right[

| Statistic         | Miles       | Kilometers |
|:-----------------:|:-----------:|:----------:|
|  `\(Sum\ of\ Squares\)` | 33.73 | 87.49   |
|    `\(s^2\)`          | 8.43 | 21.87   |
|    `\(SD\)`           | 2.91 | 4.68   |

]

---
count: false

## Why SD? Why not just variance?

+ To illustrate this, let's look at an example with distance in miles and the corresponding values in kilometers:

.pull-left[

| Miles | Kilometers|
|:-----:|:---------:|
| 4.25 | 6.84       |
| 2.61 | 4.20       |
| 1.13 | 1.82       |
| 5.89 | 9.48       |
| 8.60 | 13.85      |

+ Miles = km/1.61

]

.pull-right[

| Statistic         | Miles       | Kilometers |
|:-----------------:|:-----------:|:----------:|
|  `\(Sum\ of\ Squares\)` | 33.73 | 87.49   |
|    `\(s^2\)`          | 8.43 | 21.87   |
|    `\(SD\)`           | 2.91 | 4.68   |

+ `\(4.68/1.61 = 2.91\)`

+ `\(2.91 = 2.91\)` 

+ This now works, because SD values are measured in the same units as the original data
]

---
## A Note on Notation

+ We use slightly different notations when referring to point-estimates versus population parameters:

.center[

| Value              | Population | Sample          |
|:------------------:|:----------:|:---------------:|
| Mean               |  `\(\mu\)`     | `\(M\)` or `\(\bar{x}\)`|
| Standard Deviation | `\(\sigma\)`   | `\(SD\)` or `\(s\)`     |
| Sample Size        | `\(N\)`        | `\(n\)`             |

]


---
class: center, inverse, middle

## Questions?

---
## Describing your data: Probability distributions

.pull-left[

+ A probability distribution is a way to visualise the probability of specific observations

+ These distributions give us an idea of how unusual or rare a specific observation is

+ Specifically, we can compute the probability of a specific range of values within a distribution
]


.pull-right[

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-31-1.svg)&lt;!-- --&gt;


]

--

&gt; **Test Your Understanding:** Which value of x is most common, according to the probability distribution seen here? Which values are less common?

---
## Describing your data: Probability distributions

.pull-left[

+ We can also use probability distributions to compute the probability of value beyond a specific point on the distribution. 

+ Imagine we have a range of observations whose values fall between 8 and 32 that are distributed as pictured.

+ Let's say we randomly select an observation from our dataset.

]

.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-32-1.svg)&lt;!-- --&gt;
]

---
## Describing your data: Probability distributions

.pull-left[

+ We can also use probability distributions to compute the probability of value beyond a specific point on the distribution.

+ Imagine we have a range of observations whose values fall between 8 and 32 that are distributed as pictured.

+ Let's say we randomly select an observation from our dataset.

+ What is the likelihood our randomly selected observation is at least 25?

]

.pull-right[

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-33-1.svg)&lt;!-- --&gt;

]


---
count: false

## Describing your data: Probability distributions

.pull-left[

+ We can also use probability distributions to compute the probability of value beyond a specific point on the distribution.

+ Imagine we have a range of observations whose values fall between 8 and 32 that are distributed as pictured.

+ Let's say we randomly select an observation from our dataset.

+ What is the likelihood our randomly selected observation is at least 25?

+ ~95% of our observations are less than 25. This means we only have about a 5% chance of randomly selecting an observation of at least 25. 

]

.pull-right[

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-34-1.svg)&lt;!-- --&gt;
]

---
## Probability Distributions

+ Why does this matter?

--

+ Many of the statistical tests we will learn about in this course all involve testing the probability of a specific value of a test statistic, given that `\(H_0\)` is true. 

+ In other words, if `\(H_0\)` is true, how likely is it that we would get results at least as extreme as ours?

+ If the value is unusual enough (i.e., if it is highly unlikely we would see the value if the null is true), we reject `\(H_0\)`


---
class: inverse, center, middle

## Questions?

---
## The normal distribution

+ A probability distribution where values around the mean are most common, and values further from the mean are increasingly less common.

+ AKA the bell curve, a Gaussian distribution

--

&gt; **Test Your Understanding:** What kinds of variables can you think of that might follow a normal distribution? 

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Its key parameters are mean and standard deviation

]
.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-35-1.svg)&lt;!-- --&gt;
]

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Its key parameters are mean and standard deviation
  

]
.pull-right[

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-36-1.svg)&lt;!-- --&gt;

Adjusting the mean changes where the curve is centered on the `\(x\)`-axis

]

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Its key parameters are mean and standard deviation
  

]
.pull-right[

![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-37-1.svg)&lt;!-- --&gt;

Adjusting the `\(SD\)` changes the shape of the curve

]

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Its key parameters are mean and standard deviation

  + **68%** of scores fall within **1 SD** of the mean

]
.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-38-1.svg)&lt;!-- --&gt;
]

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Its key parameters are mean and standard deviation

  + 68% of scores fall within 1 SD of the mean
  + **95%** of scores fall within **~2 SD** of the mean (exactly 1.96 SD of the mean)

]
.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-39-1.svg)&lt;!-- --&gt;
]

---
## The normal distribution
.pull-left[
**Characteristics of a normal distribution**

+ Unimodal

+ Its key parameters are mean and standard deviation

  + 68% of scores fall within 1 SD of the mean
  + 95% of scores fall within ~2 SD of the mean (exactly 1.96 SD of the mean)
  + **99.75%** of scores fall within **3 SD** of the mean

]
.pull-right[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-40-1.svg)&lt;!-- --&gt;
]

---
## The normal distribution

&gt; **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-41-1.svg)&lt;!-- --&gt;
]

---
## The normal distribution

&gt; **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-42-1.svg)&lt;!-- --&gt;
]

---
## The normal distribution

&gt; **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-43-1.svg)&lt;!-- --&gt;
]

---

## The normal distribution

&gt; **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-44-1.svg)&lt;!-- --&gt;
]

---
## The normal distribution

&gt; **Test your understanding:** You have given participants the WAIS-IV, which is an IQ test that has been normalised so that the mean is 100 and the SD is 15. Scores are normally distributed. What value do we expect at each point on this normal distribution?

.center[
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-45-1.svg)&lt;!-- --&gt;
]


---
## Assessing Normality in Data

+ Many of the parametric statistical tests we'll be using are most reliable when data are normally distributed

&gt; **Test Your Understanding:** In a perfectly normal distribution, how are the mean, median, and mode distributed?


---
count: false

## Assessing Normality in Data

+ Many of the parametric statistical tests we'll be using are most reliable when data are normally distributed

+ Not all data are normally distributed
    + **Skewness**

.pull-left[
.center[**Negatively Skewed**]
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-46-1.svg)&lt;!-- --&gt;
]

.pull-right[
.center[**Positively Skewed**]
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-47-1.svg)&lt;!-- --&gt;
]

---
## Assessing Normality in Data

+ Many of the parametric statistical tests we'll be using are most reliable when data are normally distributed

+ Not all data are normally distributed
    + **Skewness**
    + **Kurtosis**

.pull-left[
.center[**Platykurtic**]
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-48-1.svg)&lt;!-- --&gt;
]

.pull-right[
.center[**Leptokurtic**]
![](Week01_ExploringData_Lecture_files/figure-html/unnamed-chunk-49-1.svg)&lt;!-- --&gt;
]

---
## Assessing Normality in Data

+ Can visually assess histograms

+ Can also assess using statistical tests:

  + For samples &lt; 50, could use the *Shapiro-Wilk Test*

  + For samples &gt; 50, could use the *Kolmogorovâ€“Smirnov Test*

  + Significant results on these tests indicate that normality has been violated

+ Can also check the skewness and kurtosis values
  + Values further from 0 indicate greater levels of skewness or kurtosis

---
class: center, inverse, middle

## Questions?

---
exclude: true

## Wooclap questions slide!

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
