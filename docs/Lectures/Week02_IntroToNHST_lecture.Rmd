---
title: "<b> Introduction to Null-Hypothesis <br> Statistical Testing </b>"
subtitle: "Psychological Research Methods:<br>Data Management & Analysis<br><br> "
author: "Monica Truelove-Hill"
institute: "Department of Clinical Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#18778C",
  header_color = "#000000",
  header_font_google = google_font("Jost"),
  header_font_weight = 500,
  text_font_google = google_font("Jost", "300", "300i", "500", "500i"),
  code_font_google = google_font("Source Code Pro"),
  text_bold_color = '#4CA384',
  text_slide_number_color = '#18778C',
  text_font_size = '16pt'
)
```

```{r, echo = F, message = F, warning = F}
library(tidyverse)
library(rstatix)

knitr::opts_chunk$set(dev = 'svg')

baseColor <- '#4CA384'
accent1 <- '#9AD079'
accent2 <- '#18778C'
accent3 <- '#19424C'
```

## This Week's Key Topics

+ The Null Distribution

+ $\alpha$

+ $p$-Values


---
## Hypotheses

+ **Null Hypothesis ( $H_0$ ):** There is no difference, effect, or association between variables; any experimentally observed difference is due to chance

+ **Alternative Hypothesis ( $H_1$ ):** There is a relationship or association between variables

--

+ When conducting null-hypothesis statistic testing, we attempt to determine which action is correct:
  + Reject $H_0$
  + Fail to reject $H_0$

--

+ The burden of proof is on $H_1$

  + Assume $H_0$ is accurate until there is sufficient evidence that it is not
  
---
## Assessing Evidence


+ In psychology, we rely on empirical evidence to draw conclusions

  + In other words, we gather data and look for consistent patterns within the data that support (or refute) our ideas

--
  
+ Statistical testing allows us to evaluate the strength of the evidence against $H_0$

--

  + We use our observations to calculate a statistical value, then compute the likelihood of this value occurring under the constraints of $H_0$
  
--
  
  + We use this **probability** to make a decision about $H_0$:
      + If the observed value is unlikely to occur under $H_0$, we consider this sufficient evidence to reject it
      + If the observed value is likely to occur under $H_0$, we don't reject $H_0$, because we haven't gathered sufficient evidence against it.


---
## Frequency vs Probability Distributions

+ Recall that a frequency distribution shows the frequency of each possible observation:

.pull-left[

```{r, echo=F, fig.width=7, fig.height=4}
set.seed(208)
# Categorical distribution plot
dat <- data.frame(x=sample(c('Heads', 'Tails'), size = 40, replace = T, prob = c(.5, .5)), y = rnorm(n = 40))

ggplot(dat, aes(x)) + geom_bar(fill=baseColor, color = accent3) +
  scale_y_continuous(breaks=seq(0, 30, by = 5)) +
  labs(y='Frequency') +
  theme(axis.text = element_text(size=14),
        axis.title.x = element_blank(),
        axis.title.y = element_text(size = 16, face = 'bold'))
```
.center[**Categorical Distribution**]
]

.pull-right[

```{r, echo=F, fig.width=7, fig.height=4, warning = F}
ggplot(dat, aes(y)) + geom_histogram(fill=baseColor, color=accent3, bins=12) +
  labs(y='Frequency') +
  scale_y_continuous(breaks=seq(0, 14, by = 1)) +
  scale_x_continuous(limits = c(-3, 3)) +
  theme(axis.text = element_text(size=14),
        axis.title.y = element_text(size=14, face = 'bold'),
        axis.title.x = element_blank())
```
.center[**Continuous Distribution**]
]

---

## Probability Distributions

+ A probability distribution shows the probability of randomly selecting an observation (or range) from the data:

.pull-left[

```{r, echo=F, fig.width=7, fig.height=4}
pDat <- data.frame(Outcome = unique(dat$x), Probability = as.numeric(table(dat$x)/nrow(dat)))

ggplot(pDat, aes(x=Outcome, y=Probability)) + 
  geom_bar(stat='identity', color = accent3, fill=baseColor) +
  scale_y_continuous(breaks=seq(0, .7, .1)) +
  theme(axis.text=element_text(size = 14),
        axis.title.y=element_text(size = 16, face = 'bold'),
        axis.title.x = element_blank())
```
.center[**Categorical Probability Distribution**]
]

.pull-right[

```{r, echo=F, fig.width=7, fig.height=4, warning = F}
ggplot(dat, aes(x=y)) + 
  stat_function(fun = dnorm, geom = 'line', args = c(mean=mean(dat$y), sd = sd(dat$y)), linewidth = 1.5, color = baseColor) +
  scale_x_continuous(limits = c(-3, 3)) + 
  scale_y_continuous(breaks=seq(0, .5, by = .1)) +
  theme(axis.text.x = element_text(size=14),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title = element_blank())

```
.center[**Continuous Probability Distribution**]
]

---
## Continuous Probability Distributions

.pull-left[

+ Probability distributions allow you to visualise the probability of specific observations

+ Specifically, we can compute the probability of a specific **range** of values within a continuous distribution
]

.pull-right[

```{r, echo = F, fig.height=3.5}
ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
  stat_function(fun=dnorm, geom = "line", linewidth = 1.5) + 
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14, face = 'bold'),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank()) +
  geom_hline(yintercept = 0, linewidth = 1.5)

```
]

--

> Why a range? Why can't we compute the probability of a single score?

---
## Continuous Probability Distributions

> Why a range? Why can't we compute the probability of a single score?

.center[
```{r, echo = F, fig.height = 4.5, fig.width = 8}

(conPlot <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) + stat_function(fun=dnorm, geom = "line", linewidth = 1.5) +
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14, face = 'bold'),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank()) +
  geom_hline(yintercept = 0, linewidth = 1.5) +
  geom_vline(xintercept = 2.4822, color = baseColor, linewidth = 1.5))
```
]

---
## Continuous Probability Distributions

> Why a range? Why can't we compute the probability of a single score?

.center[
```{r, echo = F, fig.height = 4.5, fig.width = 8}
conPlot + coord_cartesian(xlim=c(2, 3))
```
]

---
## Continuous Probability Distributions

> Why a range? Why can't we compute the probability of a single score?

.center[
```{r, echo = F, fig.height = 4.5, fig.width = 8}
conPlot + coord_cartesian(xlim=c(2.45, 2.52))
```
]

---

## Continuous Probability Distributions

> Why a range? Why can't we compute the probability of a single score?

.center[
```{r, echo = F, fig.height = 4.5, fig.width = 8}
conPlot + coord_cartesian(xlim=c(2.475, 2.488))
```
]

--
> Because technically, continuous values go on infinitely, so the probability of any single value is so low, it's approximately 0

---

## Continuous Probability Distributions

.pull-left[
+ Instead, the probability of a range is determined by computing the **area under the curve (AUC)** within that range.


]

.pull-right[
```{r, echo = F, fig.height=4}
testDat <- ggplot(data.frame(x = c(8, 32)), aes(x = x)) +
  stat_function(fun=dnorm, args= list(20, 3), geom = "line", linewidth = 1.5) +
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14, face = 'bold'),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.y = element_blank()) +
  geom_hline(yintercept = 0, linewidth = 1.5)

testDat
```
]
---

## Continuous Probability Distributions

.pull-left[
+ Instead, the probability of a range is determined by computing the **area under the curve (AUC)** within that range.

+ Imagine a range of observations with values between 8 and 32 that are distributed as pictured.
  
  > **Check Your Understanding:** If you were to pick an observation, what is the probability that it will be a value between 8 and 32?


]

.pull-right[
```{r, echo = F, fig.height=4}
testDat + geom_vline(xintercept = 8, color = accent3, linewidth = 1.5) +
  geom_vline(xintercept = 32, color = accent3, linewidth = 1.5)
```
]

---
## Continuous Probability Distributions

.pull-left[
+ Instead, the probability of a range is determined by computing the **area under the curve (AUC)** within that range.

+ Imagine a range of observations with values between 8 and 32 that are distributed as pictured.

  > **Check Your Understanding:** If you were to pick an observation, what is the probability that it will be a value between 8 and 32?

]

.pull-right[
```{r, echo = F, fig.height=4}
testDat + geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = baseColor, xlim=c(8, 32), alpha = .8) + 
  annotate(geom = 'text', label = '100% of \n the data', x = 20, y = .05, size = 7, color ='white') +
  geom_vline(xintercept = 8, color = accent3, linewidth = 1.5) +
  geom_vline(xintercept = 32, color = accent3, linewidth = 1.5)
```
]

---
## Continuous Probability Distributions

.pull-left[

+ Instead, the probability of a range is determined by computing the **area under the curve (AUC)** within that range.

+ Imagine a range of observations with values between 8 and 32 that are distributed as pictured.

  + If we randomly select an observation from the data, what is the likelihood it will be *at least* 25?


]

.pull-right[

```{r, echo = F, fig.height=4}
testDat + 
    geom_vline(xintercept = 25, color = accent3, linewidth = 1.5)
```

]


---
count: false

## Continuous Probability Distributions

.pull-left[
+ Instead, the probability of a range is determined by computing the **area under the curve (AUC)** within that range.

+ Imagine a range of observations with values between 8 and 32 that are distributed as pictured.

  + If we randomly select an observation from the data, what is the likelihood it will be *at least* 25?

  + ~95% of the observations are less than 25. This means we only have about a 5% chance of randomly selecting an observation of at least 25. 

]

.pull-right[

```{r, echo = F, fig.height=4}
testDat + 
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = baseColor, xlim=c(8, 25), alpha = .8) +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = accent2, xlim=c(25, 30), alpha = .8) +
  annotate('text', label = '95%', x = 20, y = .05, color = 'white', size = 7) + 
  annotate('text', label = '5%', x = 26, y = .01, color = 'white', size = 7) +
  geom_vline(xintercept = 25, color = accent3, linewidth = 1)
```
]

---
## Continuous Probability Distributions

.pull-left[

```{r, echo = F, fig.height=5}
testDat +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = baseColor, xlim=c(8, 24), alpha = .8) +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = accent2, xlim=c(24, 30), alpha = .8) + 
  geom_vline(xintercept = 24, color = accent1, linewidth = 1.5)
```

]

.pull-right[
```{r, echo = F, fig.height=5}
testDat +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = accent2, xlim=c(8, 18), alpha = .8) +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = baseColor, xlim=c(18, 30), alpha = .8) +
  geom_vline(xintercept = 18, color = accent3, linewidth = 1.5)
```

]

> **Test Your Understanding:** Is it more unusual to have a score of 24 or more or a score of 18 or less?

---
count: false

## Continuous Probability Distributions

.pull-left[
```{r, echo = F, fig.height=5}
testDat +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = baseColor, xlim=c(8, 24), alpha = .8) +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = accent2, xlim=c(24, 30), alpha = .8) +
  annotate('text', label = '91%', x = 18, y = .02, color = 'white', size = 7) + 
  annotate('text', label = '9%', x = 25, y = .02, color = 'white', size = 7)+ 
  geom_vline(xintercept = 24, color = accent1, linewidth = 1.5)
```
]

.pull-right[
```{r, echo = F, fig.height=5}
testDat +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = accent2, xlim=c(8, 18), alpha = .8) +
  geom_area(stat = 'function', fun = dnorm, args= list(20, 3), fill = baseColor, xlim=c(18, 30), alpha = .8) +
  annotate('text', label = '25%', x = 16, y = .02, color = 'white', size = 7) + 
  annotate('text', label = '75%', x = 22, y = .02, color = 'white', size = 7) + 
  geom_vline(xintercept = 18, color = accent3, linewidth = 1.5)
```
]

> **Test Your Understanding:** Is it more unusual to have a score of 24 or more or a score of 18 or less?

---
## Continuous Probability Distributions

+ Why does this matter?

--

+ The statistical tests we will be using work by testing the probability of our results given the null hypothesis

  + In other words, if the null hypothesis is true, how likely is it that we would get results at least as extreme as ours?

+ If our results are unusual enough, we reject the null hypothesis.

---
class: center, inverse, middle

## Questions?

---
## Testing Against the Null Hypothesis

+ In order to make a decision whether our data/values are unusual, we need to have an understanding of what values we might expect to see if the null hypothesis were true.

--

> **Test Your Understanding:** Given the following distributions, do you think a value of 20 would be unusual?


--
.pull-left[
```{r, echo = F, fig.height=4}
set.seed(211)
ggplot(data.frame(x=rnorm(100, mean = 18, sd = 3)), aes(x)) + 
  geom_histogram(binwidth = .75, fill = baseColor, color = accent3) +
  geom_vline(xintercept = 20, color = accent2, linewidth = 1) + 
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 16, face = 'bold'))
```
]

--

.pull-right[
```{r, echo = F, fig.height=4}
set.seed(311)
ggplot(data.frame(x=rnorm(100, mean = 13, sd = 3)), aes(x)) + 
  geom_histogram(binwidth = .75, fill = baseColor, color = accent3) +
  geom_vline(xintercept = 20, color = accent2, linewidth = 1) + 
  theme(axis.text = element_text(size = 14),
        axis.title = element_text(size = 16, face = 'bold'))
```
]



???

+ A value of 20 tells us nothing without context


---
## Null Distributions

+ Many inferential statistical tests evaluate significance by comparing results to a predefined probability distribution known as the **null distribution**

+ The null distribution is the probability distribution of a statistic **given that the null hypothesis is true**. 

+ Each statistical test is associated with a separate null distribution

---

## Null Distributions

.pull-left.center[
```{r, echo = F, fig.height=3, fig.width=4.5}
ggplot(data.frame(x=c(0, 10)), aes(x=x)) +
  stat_function(fun=dchisq, geom='line', args=c(df = 2), color = accent1, linewidth=1.5) +
  scale_y_continuous(limits=c(0, .52), breaks = seq(0, .5, .1)) +
  labs(x = expression(chi^2)) +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 16, face = 'bold'),
        axis.text.x = element_text(size = 14))

```
]


.pull-right.center[
```{r, echo = F, fig.height=3, fig.width=4.5}
ggplot(data.frame(x=c(-6, 6)), aes(x=x)) +
  stat_function(fun=dt, geom='line', args=c(df = 20), color = accent2, linewidth=1.5) +
  labs(x = 't-statistic') +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 16, face = 'bold'),
        axis.text.x = element_text(size = 14))

```
]

.center[
```{r, echo = F, fig.height=3, fig.width=4.5}
ggplot(data.frame(x=c(0, 5)), aes(x=x)) +
  stat_function(fun=df, geom='line', args=c(df1 = 10, df2=100), color = baseColor, linewidth=1.5) +
  labs(x = 'F-statistic') +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 16, face = 'bold'),
        axis.text.x = element_text(size = 14))

```
]

---
## Comparing Results to Null Distribution

+ When you run a statistical test, you:

  1. Compute a test statistic based on your data
  
  2. Calculate the probability of obtaining this statistic if the null were true
  
  3. Use this probability to make a decision whether to reject the null hypothesis.
  
---
## Comparing Results to Null Distribution

.pull-left[.center[
```{r, echo = F, fig.height=4, fig.width=5}
baset <- ggplot(data.frame(x=c(-6, 6)), aes(x=x)) +
  stat_function(fun=dt, geom='line', args=c(df = 50), linewidth=1.5) + 
  labs(x = 't-statistic') +
  theme(axis.text.y = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.title.x = element_text(size = 12, face = 'bold'),
        axis.text.x = element_text(size = 10)) +
  geom_hline(yintercept = 0, linewidth = 1.5)

baset + geom_vline(xintercept = .75, linewidth = 1.5) +
  annotate('text', label = 't = 0.75', x = 2.25, y = .3, size = 5)
```
]]


---
## Comparing Results to Null Distribution

.pull-left[.center[
```{r, echo = F, fig.height=4, fig.width=5}
(ns <- baset +
  annotate('text', label = 't = 0.75', x = 2.25, y = .3, size = 5) +
  geom_area(stat = 'function', fun = dt, args= list(df = 50), xlim=c(-6, .75), fill = baseColor, alpha = .8) +
  annotate('text', label = '~77%', x = -.4, y = .05, color = 'white', size = 5) + 
  geom_area(stat = 'function', fun = dt, args= list(df = 50), xlim=c(.75, 6), fill = accent2, alpha = .8) +
  annotate('text', label = '~23%', x = 1.4, y = .05, color = 'white', size = 5) +
  geom_vline(xintercept = .75, linewidth = 1.5))
```
]]

---
count: false

## Comparing Results to Null Distribution

.pull-left[.center[
```{r, echo = F, fig.height=4, fig.width=5}
ns
```
<B>Not so unusual.</B>
]]

--

.pull-right[.center[
```{r, echo = F, fig.height=4, fig.width=5}
(sigPlot <- baset + 
  geom_vline(xintercept = 3.05, linewidth = 1.5) +
  annotate('text', label = 't = 3.05', x = 4.5, y = .3, size = 5))
```
]]

---
count:false

## Comparing Results to Null Distribution

.pull-left[.center[
```{r, echo = F, fig.height=4, fig.width=5}
ns
```
<B> Not so unusual. </B>
]]

.pull-right[.center[
```{r, echo = F, fig.height=4, fig.width=5}
sigPlot + 
  geom_area(stat = 'function', fun = dt, args= list(df = 50), xlim=c(-6, 3.05), fill = baseColor, alpha = .8) +
  annotate('text', label = '~99.8%', x = 0, y = .05, color = 'white', size = 5)
```
<B> Quite unusual! </B>
]]

---
class: center, inverse, middle

## Questions?

---
## $p$ - values

.pull-left[
+ The $p$-value is the **probability** of obtaining data at least as extreme as ours, given that the null hypothesis is true.

+ It is not:
  + The likelihood that the null hypothesis is true.
  + The likelihood that our hypothesis is false
]

---
count: false

## $p$ - values

.pull-left[
+ The $p$-value is the **probability** of obtaining data at least as extreme as ours, given that the null hypothesis is true.

+ It is not:
  + The likelihood that the null hypothesis is true.
  + The likelihood that our hypothesis is false

+ It provides insight into the strength of our evidence against the null hypothesis. 

+ If $p$-value passes a specific threshold, we consider our results to be **significant**, and $H_0$ is rejected.

]

--

.pull-right[
```{r, echo=F, fig.height=5, fig.width=6}
ns + annotate('text', label = 'p = .230', x = 4.5, y = .05, size = 6, color = accent3) +
  annotate('segment', x = 2.25, xend = 3.2, y = .045, yend = .045, color = accent3,
           arrow = arrow(type = "closed", length = unit(0.02, "npc"), ends = 'first'))
```
]


---

## $\alpha$

+ The 'threshold' for significance is known as alpha, $\alpha$

+ If the $p$-value is less than the predetermined $\alpha$ threshold, $H_0$ is rejected

+ But what, exactly, does $\alpha$ reflect?

---
## Errors

+ Whether the decision is made to reject or fail to reject $H_0$, you may be making an error.

+ Basically, what you find in your sample isn't actually what is true of the population.

--

+ Two types of errors:

  + **Type I Error:** You reject the $H_0$ when it is actually true (i.e. you suggest there is an effect or an association when there really isn't)
  
  + **Type II Error:** You fail to reject the $H_0$ when you actually should (i.e. you don't find an effect or association that actually exists)

---
## $\alpha$

+ $\alpha$ reflects the probability of making a Type I error

+ It is the likelihood of rejecting $H_0$ when it is actually true.
  
+ You choose your desired $\alpha$ value before you run any analyses. 

  + The most commonly used $\alpha$ is .05, but may sometimes be set at .01 or .001.
  
  + If $\alpha$ is set at .05, it means there is a 5% risk of rejecting $H_0$ when it shouldn't be. 

---
class: center, inverse, middle

## Questions?
---
## One-Tailed vs Two-Tailed Tests

.pull-left[

+ When evaluating evidence against $H_0$, our threshold for what values are considered to be *extreme* depends on whether we're running a one-tailed or two-tailed test.

]

---
## One-Tailed vs Two-Tailed Tests

.pull-left[

+ When evaluating evidence against $H_0$, our threshold for what values are considered to be *extreme* depends on whether we're running a one-tailed or two-tailed test.

+ With a **one-tailed test**, we're only interested in values in a single tail of a distribution

  + If $\alpha$ is set at .05, we check that our observation is in the highest 5% of values *or* the lowest 5% of values

]

.pull-right[

```{r, echo = F, fig.height=2.5}
ggplot(data = data.frame(t = c(-5, 5)), aes(x=t)) +
  stat_function(fun=dt, geom='line', args=c(df = 29), color = accent3, linewidth=1.5) +
  geom_area(stat = 'function', fun = dt, args= list(df = 29), fill = accent1,
            xlim=c(qt(.05, df = 29, lower.tail = F), 5), alpha = .8) +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        axis.line.y = element_blank(),
        axis.ticks = element_blank()) +
  annotate('text', x = 3, y = .3, parse = T, label = paste('alpha == .05'), size = 8, color = accent2) +
  geom_hline(yintercept = 0, linewidth = 1.5)
```

.center[
<b>OR</b>
]

```{r, echo = F, fig.height=2.5}
ggplot(data = data.frame(t = c(-5, 5)), aes(x=t)) +
  stat_function(fun=dt, geom='line', args=c(df = 29), color = accent3, linewidth=1.5) +
  geom_area(stat = 'function', fun = dt, args= list(df = 29), fill = accent1,
            xlim=c(-5, qt(.05, df = 29)), alpha = .8) +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        axis.line.y = element_blank(),
        axis.ticks = element_blank()) +
  annotate('text', x = -3, y = .3, parse = T, label = paste('alpha == .05'), size = 8, color = accent2) +
  geom_hline(yintercept = 0, linewidth = 1.5)
```
]

---
## One-Tailed vs Two-Tailed Tests

.pull-left[

+ When evaluating evidence against $H_0$, our threshold for what values are considered to be *extreme* depends on whether we're running a one-tailed or two-tailed test.

+ With a **two-tailed test**, we're interested in values in both tails of a distribution

  + If $\alpha$ is set at .05, we check that our observation is in the *most extreme* 5% of values, whether they are higher or lower
  
  + 5% is split equally between the two tails

]

.pull-right[

```{r, echo = F, fig.height=4}
ggplot(data = data.frame(t = c(-5, 5)), aes(x=t)) +
  stat_function(fun=dt, geom='line', args=c(df = 29), color = accent2, linewidth=1.5) +
  geom_area(stat = 'function', fun = dt, args= list(df = 29), fill = accent1,
            xlim=c(qt(.025, df = 29, lower.tail = F), 5), alpha = .8) +
  geom_area(stat = 'function', fun = dt, args= list(df = 29), fill = accent1,
            xlim=c(-5, qt(.025, df = 29)), alpha = .8) +
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        axis.line.y = element_blank(),
        axis.ticks = element_blank()) +
  annotate('text', x = 3, y = .3, parse = T, label = paste('alpha == .05'), size = 8, color = accent2) +
  annotate('text', x = 3.25, y = .05, parse = T, label = paste('alpha/2 == .025'), size = 6, color = accent2) +
  annotate('text', x = -3.25, y = .05, parse = T, label = paste('alpha/2 == .025'), size = 6, color = accent2) +
  annotate('segment', x= -2.25, xend = 3, y = .06, yend = .28, color = accent2, linewidth = 1, linetype = 'dashed') +
  annotate('segment', x= 2.4, xend = 3, y = .06, yend = .28, color = accent2, linewidth = 1, linetype = 'dashed') +
  geom_hline(yintercept = 0, linewidth = 1.5)
```

]

---
## Putting it Together

+ When we run a statistical test, our results are compared against the null distribution, which is the probability of the results given the null hypothesis is true.

+ If the probability of our outcome (the $p$-value) is less than the $\alpha$ threshold, it means the outcome falls into the range that we've designated as extreme.

+ Because it's really unlikely that these results would occur if the null hypothesis were true, we consider this to be sufficient evidence against the null hypothesis, and we reject it.

---
class: center, inverse, middle

## Questions?

