---
title: "<b> Correlation </b>"
subtitle: "Psychological Research Methods:<br>Data Management & Analysis<br><br> "
author: "Monica Truelove-Hill"
institute: "Department of Clinical Psychology<br>The University of Edinburgh"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#18778C",
  header_color = "#000000",
  header_font_google = google_font("Jost"),
  header_font_weight = 500,
  text_font_google = google_font("Jost", "300", "300i", "500", "500i"),
  code_font_google = google_font("Source Code Pro"),
  text_bold_color = '#4CA384',
  text_slide_number_color = '#18778C',
  text_font_size = '16pt'
)
```

```{r, echo = F, message = F, warning = F}
library(tidyverse)
library(kableExtra)
library(faux)

knitr::opts_chunk$set(dev = 'svg')

# baseColor <- "#18778C"
# accent1 <- '#D95829'
# accent2 <- '#BF3326'
# accent3 <- '#F29422'

baseColor <- '#4CA384'
accent1 <- '#9AD079'
accent2 <- '#18778C'
accent3 <- '#19424C'
```

## This Week's Learning Objectives

After this week, you should be able to:

1. Describe the difference between variance, covariance, and correlation

2. Calculate both covariance and correlation

3. Interpret the correlation coefficient

4. Perform and interpret the results of a significance test of your correlation

5. Understand which form of correlation is most appropriate to use with your data

---
## Data for Today

.pull-left[
+ Correlation is a measure of the relationship between two variables

+ The primary method we'll use is Pearson's correlation, which measures the association between two **continuous** variables

+ When investigating the relationship between two continuous variables, we often visualise them using scatterplots
]

--

.pull-right[

```{r, echo=F, message = F, fig.width=5, fig.height=3.5}
set.seed(526)
dat <- rnorm_multi(100, mu = c(90, 13), sd = c(30,  7), varnames = c('daysInProgram', 'maxDistance'), r = .7)

dat$daysInProgram[dat$daysInProgram<0] <- dat$daysInProgram[dat$daysInProgram<0]-min(dat$daysInProgram)
dat$maxDistance[dat$maxDistance<0] <- dat$maxDistance[dat$maxDistance<0]-min(dat$maxDistance)

ggplot(dat, aes(daysInProgram, maxDistance)) + geom_point(shape = 21, size = 3, color = accent3, fill = baseColor) + 
  labs(x='Days In Program', y='Max Distance (miles)') + 
  theme(axis.text = element_text(size=12), axis.title = element_text(size=14, face = 'bold'))
```
]

---
## Variance Refresher

.pull-left[
$$s^2_x = \frac{\sum_{i=1}^{n}{(x_i - \bar{x})}^2}{n-1}$$

+ **Variance:** Deviance around the mean of a single variable
]

.pull-right[
```{r, echo = F, fig.height=3, fig.width=5}
sampleDat <- data.frame(Names=c('Alfred', 'Bernard', 'Clarence', 'Dorothy', 'Edna', 'Flora', 'Geraldine'),
                    daysInProgram=c(117, 99, 103, 95, 136, 126, 108),
                    maxDistance=c(8.53, 10.57, 8.01, 14.63, 27.03, 22.22, 6.77))


(p1 <- ggplot(sampleDat, aes(Names, daysInProgram)) + geom_point(size=2, colour = baseColor) +
  labs(x='Participant Name', y = 'Days in Program') +
  theme(axis.text = element_text(size=10), axis.title = element_text(size=12, face = 'bold')) +
  scale_y_continuous(breaks=seq(80, 140, by = 20), limits = c(80, 140)))


```

]


---
count: false

## Variance Refresher

.pull-left[
$$s^2_x = \frac{\sum_{i=1}^{n}{(x_i - \bar{x})}^2}{n-1}$$

+ **Variance:** Deviance around the mean of a single variable

+ Raw deviation is the distance between each person's days in the program and the mean number of days in the program. 
]

.pull-right[
```{r, echo = F, fig.height=3, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  labs(x='Participant Name', y = 'Days In Program') + 
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= baseColor)
```
]

---
count: false

## Variance Refresher

.pull-left[
$$s^2_x = \frac{\sum_{i=1}^{n}{(x_i - \bar{x})}^2}{n-1}$$

+ **Variance:** Deviance around the mean of a single variable

+ Raw deviation is the distance between each person's days in the program and the mean number of days in the program. 

+ To get the variance, we:
  1. Square the values to get rid of the negative
  2. Sum them up and divide by $n-1$ to get the average deviation of the group from its mean.
]

.pull-right[
```{r, echo = F, fig.height=3, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= baseColor)
```
]


---
## Covariance

.pull-left[
+ **Covariance:** A value that represents how two variables change together

+ Do $x$ and $y$ differ from their means in a similar way?
]

.pull-right[

```{r, echo = F, fig.height=2.5, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= baseColor)
```

```{r, echo = F, fig.height=2.5, fig.width=5}
p2 <- ggplot(sampleDat, aes(Names, maxDistance)) + geom_point(size=2, colour = accent2) +
  labs(x='Participant Name', y ='Max Distance (miles)') +
  theme(axis.text = element_text(size=10), axis.title = element_text(size=12, face = 'bold')) + 
  geom_hline(yintercept = mean(sampleDat$maxDistance)) + 
  geom_segment(x = sampleDat$Names, y = sampleDat$maxDistance, 
               xend = sampleDat$Names, yend = mean(sampleDat$maxDistance), linetype = "dashed",
               colour= accent2) +
  scale_y_continuous(breaks=seq(0, 30, 10), limits = c(0, 30))

p2
```

]


---
count: false

## Covariance

.pull-left[
+ **Covariance:** A value that represents how two variables change together

+ Do $x$ and $y$ differ from their means in a similar way?

+ Mathematically similar to variance:


**Variance**
$$s^2_x = \frac{\sum_{i=1}^{n}{(x_i-\bar{x})^2}}{n-1} = \frac{\sum_{i=1}^{n}{(x_i-\bar{x})(x_i-\bar{x})}}{n-1}$$



**Covariance**

$$Cov_{xy} = \frac{\sum_{i=1}^{n}{\color{#4CA384}{(x_i-\bar{x})}\color{#18778C}{(y_i-\bar{y})}}}{n-1}$$
]

.pull-right[
```{r, echo = F, fig.height=2.5, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= baseColor)
```

```{r, echo = F, fig.height=2.5, fig.width=5}
p2
```
]

---

## Covariance

.pull-left[
+ It's possible two variables are related if their observations differ proportionally from their means in a consistent way

+ Covariance gives us a sense of this...

  + High covariance suggests a stronger relationship than a lower covariance

  + Why can't we stop here? 
  
  + Why is correlation necessary? 

]


.pull-right[
```{r, echo = F, fig.height=2.5, fig.width=5}
p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= baseColor)
```

```{r, echo = F, fig.height=2.5, fig.width=5}
p2
```
]

---

## The Trouble with Covariance

.pull-left[

$$Cov_{xy}=\frac{\sum_{i=1}^n\color{#18778C}{(x_i-\bar{x})}(y_i-\bar{y})}{n-1}$$


```{r, echo = F}
sampleDat$varX <- round(sampleDat$daysInProgram-mean(sampleDat$daysInProgram),2)
sampleDat$varY <- round(sampleDat$maxDistance-mean(sampleDat$maxDistance), 2)
sampleDat$varXY <- round(sampleDat$varX*sampleDat$varY, 2)
row.names(sampleDat) <- NULL

```

| Participant           |  $x_i - \bar{x}$      |
|:----------------------|:---------------------:|
| `r sampleDat$Names[1]`| `r sampleDat$varX[1]` |
| `r sampleDat$Names[2]`| `r sampleDat$varX[2]` |
| `r sampleDat$Names[3]`| `r sampleDat$varX[3]` |
| `r sampleDat$Names[4]`| `r sampleDat$varX[4]` |
| `r sampleDat$Names[5]`| `r sampleDat$varX[5]` |
| `r sampleDat$Names[6]`| `r sampleDat$varX[6]` |
| `r sampleDat$Names[7]`| `r sampleDat$varX[7]` |
]


.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
(p3 <- p1 + geom_hline(yintercept = mean(sampleDat$daysInProgram)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$daysInProgram, 
               xend = sampleDat$Names, yend = mean(sampleDat$daysInProgram), linetype = "dashed",
               colour= baseColor) +
  geom_text(aes(label = sampleDat$varX), nudge_x = .2, y = mean(sampleDat$daysInProgram)+(sampleDat$varX/2)))
```

]

---
count: false

## The Trouble with Covariance

.pull-left[

$$Cov_{xy}=\frac{\sum_{i=1}^n(x_i-\bar{x})\color{#18778C}{(y_i-\bar{y})}}{n-1}$$

| Participant           |  $x_i - \bar{x}$      |    $y_i - \bar{y}$    |
|:----------------------|:---------------------:|:---------------------:|
| `r sampleDat$Names[1]`| `r sampleDat$varX[1]` | `r sampleDat$varY[1]` |
| `r sampleDat$Names[2]`| `r sampleDat$varX[2]` | `r sampleDat$varY[2]` |
| `r sampleDat$Names[3]`| `r sampleDat$varX[3]` | `r sampleDat$varY[3]` |
| `r sampleDat$Names[4]`| `r sampleDat$varX[4]` | `r sampleDat$varY[4]` |
| `r sampleDat$Names[5]`| `r sampleDat$varX[5]` | `r sampleDat$varY[5]` |
| `r sampleDat$Names[6]`| `r sampleDat$varX[6]` | `r sampleDat$varY[6]` |
| `r sampleDat$Names[7]`| `r sampleDat$varX[7]` | `r sampleDat$varY[7]` |
]



.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
p3 
```

```{r, echo = F, fig.width=5, fig.height=2.5}
(p4 <- p2 + geom_text(aes(label = sampleDat$varY), nudge_x = .35, y = mean(sampleDat$maxDistance)+(sampleDat$varY/2)))
```

]

---
count: false

## The Trouble with Covariance

.pull-left[

$$Cov_{xy}=\frac{\sum_{i=1}^n\color{#18778C}{(x_i-\bar{x})(y_i-\bar{y})}}{n-1}$$

| Participant           |  $x_i - \bar{x}$      |    $y_i - \bar{y}$    | $(x_i - \bar{x})(y_i - \bar{y})$   |
|:----------------------|:---------------------:|:---------------------:|:------------------------:|
| `r sampleDat$Names[1]`| `r sampleDat$varX[1]` | `r sampleDat$varY[1]` |  `r sampleDat$varXY[1]`  |
| `r sampleDat$Names[2]`| `r sampleDat$varX[2]` | `r sampleDat$varY[2]` |  `r sampleDat$varXY[2]`  |
| `r sampleDat$Names[3]`| `r sampleDat$varX[3]` | `r sampleDat$varY[3]` |  `r sampleDat$varXY[3]`  |
| `r sampleDat$Names[4]`| `r sampleDat$varX[4]` | `r sampleDat$varY[4]` |  `r sampleDat$varXY[4]`  |
| `r sampleDat$Names[5]`| `r sampleDat$varX[5]` | `r sampleDat$varY[5]` |  `r sampleDat$varXY[5]`  |
| `r sampleDat$Names[6]`| `r sampleDat$varX[6]` | `r sampleDat$varY[6]` |  `r sampleDat$varXY[6]`  |
| `r sampleDat$Names[7]`| `r sampleDat$varX[7]` | `r sampleDat$varY[7]` |  `r sampleDat$varXY[7]`  |


]


.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
p3
```

```{r, echo = F, fig.width=5, fig.height=2.5}
p4
```

]

---
count: false

## The Trouble with Covariance

.pull-left[

$$Cov_{xy}=\frac{\color{#18778C}{\sum_{i=1}^n}(x_i-\bar{x})(y_i-\bar{y})}{n-1}$$


| Participant           |  $x_i - \bar{x}$      |    $y_i - \bar{y}$    | $(x_i - \bar{x})(y_i - \bar{y})$   |
|:----------------------|:---------------------:|:---------------------:|:------------------------:|
| `r sampleDat$Names[1]`| `r sampleDat$varX[1]` | `r sampleDat$varY[1]` |  `r sampleDat$varXY[1]`  |
| `r sampleDat$Names[2]`| `r sampleDat$varX[2]` | `r sampleDat$varY[2]` |  `r sampleDat$varXY[2]`  |
| `r sampleDat$Names[3]`| `r sampleDat$varX[3]` | `r sampleDat$varY[3]` |  `r sampleDat$varXY[3]`  |
| `r sampleDat$Names[4]`| `r sampleDat$varX[4]` | `r sampleDat$varY[4]` |  `r sampleDat$varXY[4]`  |
| `r sampleDat$Names[5]`| `r sampleDat$varX[5]` | `r sampleDat$varY[5]` |  `r sampleDat$varXY[5]`  |
| `r sampleDat$Names[6]`| `r sampleDat$varX[6]` | `r sampleDat$varY[6]` |  `r sampleDat$varXY[6]`  |
| `r sampleDat$Names[7]`| `r sampleDat$varX[7]` | `r sampleDat$varY[7]` |  `r sampleDat$varXY[7]`  |
|                       |                       |                       |  **`r round(sum(sampleDat$varXY), 2)`**|

]

.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
p3
```

```{r, echo = F, fig.width=5, fig.height=2.5}
p4
```

]

---

## The Trouble with Covariance

.pull-left[

$$Cov_{xy}=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}=\frac{`r round(sum(sampleDat$varXY), 2)`}{7-1}=`r round(sum(sampleDat$varXY)/6, 2)`$$


| Participant           |  $x_i - \bar{x}$      |    $y_i - \bar{y}$    | $(x_i - \bar{x})(y_i - \bar{y})$   |
|:----------------------|:---------------------:|:---------------------:|:------------------------:|
| `r sampleDat$Names[1]`| `r sampleDat$varX[1]` | `r sampleDat$varY[1]` |  `r sampleDat$varXY[1]`  |
| `r sampleDat$Names[2]`| `r sampleDat$varX[2]` | `r sampleDat$varY[2]` |  `r sampleDat$varXY[2]`  |
| `r sampleDat$Names[3]`| `r sampleDat$varX[3]` | `r sampleDat$varY[3]` |  `r sampleDat$varXY[3]`  |
| `r sampleDat$Names[4]`| `r sampleDat$varX[4]` | `r sampleDat$varY[4]` |  `r sampleDat$varXY[4]`  |
| `r sampleDat$Names[5]`| `r sampleDat$varX[5]` | `r sampleDat$varY[5]` |  `r sampleDat$varXY[5]`  |
| `r sampleDat$Names[6]`| `r sampleDat$varX[6]` | `r sampleDat$varY[6]` |  `r sampleDat$varXY[6]`  |
| `r sampleDat$Names[7]`| `r sampleDat$varX[7]` | `r sampleDat$varY[7]` |  `r sampleDat$varXY[7]`  |
|                       |                       |                       |  **`r round(sum(sampleDat$varXY), 2)`**|

]

.pull-right[

```{r, echo = F, fig.width=5, fig.height=2.5}
p3
```

```{r, echo = F, fig.width=5, fig.height=2.5}
p4
```

]


---

## The Trouble with Covariance

+ A value of `r round(sum(sampleDat$varXY)/6, 2)` seems high...I think. Is it?

  + Maybe? But maybe not. 
  
  + Covariance is related specifically to the scales of the variables we are analysing. 
  
  + Variables with larger scales will naturally have larger covariance values.


---

## The Trouble with Covariance

+ Consider what would happen if we converted our distance data to kilometers instead of miles.

```{r, echo=F}
sampleDat$maxDistancekm <- sampleDat$maxDistance*1.61
```


.pull-left[

.center[**Miles**]

```{r, echo = 5, fig.height=3.5, fig.width=5}
p4
```


]

.pull-right[

.center[**Kilometers**]

```{r, echo = F, fig.height=3.5, fig.width=5}
sampleDat$varYkm <- round(sampleDat$maxDistancekm-mean(sampleDat$maxDistancekm),2)
sampleDat$varXYkm <- round(sampleDat$varX*sampleDat$varYkm,2)

ggplot(sampleDat, aes(Names, maxDistancekm)) + geom_point(size=2, colour = accent2) +
  labs(x='Participant Name', y = 'Max Distance (km)') + 
  theme(axis.text = element_text(size=10), axis.title = element_text(size=12, face = 'bold')) +
  scale_y_continuous(breaks=seq(20, 50, by = 10), limits = c(0, 50)) + geom_hline(yintercept = mean(sampleDat$maxDistancekm)) +
  geom_segment(x = sampleDat$Names, y = sampleDat$maxDistancekm, 
               xend = sampleDat$Names, yend = mean(sampleDat$maxDistancekm), linetype = "dashed",
               colour= accent2) +
  geom_text(aes(label = varYkm), nudge_x = .35, y = mean(sampleDat$maxDistancekm)+(sampleDat$varYkm/2))
```



]

---

## The Trouble with Covariance

.pull-left[

.center[**Miles**]

$$Cov_{xy}=`r round(sum(sampleDat$varXY)/6, 2)`$$


| Participant       |  $x_i - \bar{x}$      |    $y_i - \bar{y}$    | $(x_i - \bar{x})(y_i - \bar{y})$   |
|:------------------|:---------------------:|:---------------------:|:----------------------------------:|
| `r sampleDat$Names[1]`| `r sampleDat$varX[1]` | `r sampleDat$varY[1]` |  `r sampleDat$varXY[1]`  |
| `r sampleDat$Names[2]`| `r sampleDat$varX[2]` | `r sampleDat$varY[2]` |  `r sampleDat$varXY[2]`  |
| `r sampleDat$Names[3]`| `r sampleDat$varX[3]` | `r sampleDat$varY[3]` |  `r sampleDat$varXY[3]`  |
| `r sampleDat$Names[4]`| `r sampleDat$varX[4]` | `r sampleDat$varY[4]` |  `r sampleDat$varXY[4]`  |
| `r sampleDat$Names[5]`| `r sampleDat$varX[5]` | `r sampleDat$varY[5]` |  `r sampleDat$varXY[5]`  |
| `r sampleDat$Names[6]`| `r sampleDat$varX[6]` | `r sampleDat$varY[6]` |  `r sampleDat$varXY[6]`  |
| `r sampleDat$Names[7]`| `r sampleDat$varX[7]` | `r sampleDat$varY[7]` |  `r sampleDat$varXY[7]`  |
|                       |                       |                       |  **`r round(sum(sampleDat$varXY), 2)`**|


]

.pull-right[

.center[**Kilometers**]

$$Cov_{xy}=`r round(sum(sampleDat$varXYkm)/6, 2)`$$


| Participant           |  $x_i - \bar{x}$      |    $y_i - \bar{y}$    | $(x_i - \bar{x})(y_i - \bar{y})$   |
|:----------------------|:---------------------:|:---------------------:|:------------------------:|
| `r sampleDat$Names[1]`| `r sampleDat$varX[1]` | `r sampleDat$varYkm[1]` |  `r sampleDat$varXYkm[1]`  |
| `r sampleDat$Names[2]`| `r sampleDat$varX[2]` | `r sampleDat$varYkm[2]` |  `r sampleDat$varXYkm[2]`  |
| `r sampleDat$Names[3]`| `r sampleDat$varX[3]` | `r sampleDat$varYkm[3]` |  `r sampleDat$varXYkm[3]`  |
| `r sampleDat$Names[4]`| `r sampleDat$varX[4]` | `r sampleDat$varYkm[4]` |  `r sampleDat$varXYkm[4]`  |
| `r sampleDat$Names[5]`| `r sampleDat$varX[5]` | `r sampleDat$varYkm[5]` |  `r sampleDat$varXYkm[5]`  |
| `r sampleDat$Names[6]`| `r sampleDat$varX[6]` | `r sampleDat$varYkm[6]` |  `r sampleDat$varXYkm[6]`  |
| `r sampleDat$Names[7]`| `r sampleDat$varX[7]` | `r sampleDat$varYkm[7]` |  `r sampleDat$varXYkm[7]`  |
|                       |                       |                         |  **`r round(sum(sampleDat$varXYkm), 2)`**|



]

---

## Correlation

+ Correlation allows you to compare continuous variables across different scales without the magnitude of the variables skewing your results.

+ **Pearson's correlation**, $r$, is the standardised version of covariance:

.f4[

$$r=\frac{\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}}{\sqrt{\frac{\sum_{i=1}^n(x_i-\bar{x})^2}{n-1}}\sqrt{\frac{\sum_{i=1}^n(y_i-\bar{y})^2}{n-1}}}$$
]


---
count: false

## Correlation

+ Correlation allows you to compare continuous variables across different scales without the magnitude of the variables skewing your results.

+ **Pearson's correlation**, $r$, is the standardised version of covariance:

.f4[

$$r=\frac{\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{n-1}}{\sqrt{\frac{\sum_{i=1}^n(x_i-\bar{x})^2}{n-1}}\sqrt{\frac{\sum_{i=1}^n(y_i-\bar{y})^2}{n-1}}} = \frac{Cov_{xy}}{s_xs_y}$$
]

---
## Correlation

.pull-left[
+ By dividing covariance by the product of the standard deviations of $x$ and $y$, we remove issues with scale differences in the original variables.

+ Because of this, you can use $r$ to investigate the relationships between continuous variables with completely different ranges. 

]


.pull-right[
.center.f3[**Miles**]

<br>

$$r=\frac{`r round(sum(sampleDat$varXY)/6, 2)`}{`r round(sd(sampleDat$daysInProgram),2)`\times`r round(sd(sampleDat$maxDistance),2)`}=`r round((sum(sampleDat$varXY)/6)/(sd(sampleDat$daysInProgram)*sd(sampleDat$maxDistance)), 2)`$$

<br>

.center.f3[**Kilometers**]

<br>

$$r=\frac{`r round(sum(sampleDat$varXYkm)/6, 2)`}{`r round(sd(sampleDat$daysInProgram),2)`\times`r round(sd(sampleDat$maxDistancekm),2)`}=`r round((sum(sampleDat$varXYkm)/6)/(sd(sampleDat$daysInProgram)*sd(sampleDat$maxDistancekm)), 2)`$$

]

---
class: inverse, middle, center

## Questions?

---
## Interpreting $r$

+ Values of $r$ can fall between -1 and 1.

  + Values closer to 0 indicate a weaker relationship
  
  + More extreme values indicate a stronger association

--

+ Interpretation (somewhat arbitrary):

.center[

| Value   | Interpretation |
|:-------:|:--------------:|
| < .1    | Neglible       |
| .1-.3   | Weak           |
| .3-.6   | Moderate       |
|  > .6   | Strong         |

]

---
## Interpreting $r$

+ Values of $r$ fall between -1 and 1.

  + Values closer to 0 indicate a weaker relationship
  
  + More extreme values indicate a stronger association

.center[
```{r, echo = F, message = F, warning = F, fig.height=3.75, fig.width = 9}
set.seed(504)
strCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = 0.8)
strCor$maxDistance[strCor$maxDistance<=0] <- 5
strCor$daysInProgram[strCor$daysInProgram<=0] <- 2
strCor$corrStrength <- 'Strong'

set.seed(1022)
modCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = 0.45)
modCor$corrStrength <- 'Moderate'
modCor$maxDistance[modCor$maxDistance<=0] <- 5

set.seed(86)
lowCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = 0.15)
lowCor$corrStrength <- 'Weak'

set.seed(86)
noCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = 0)
noCor$corrStrength <- 'None'

corDat <- rbind(strCor, modCor, lowCor, noCor)

corDat$corrStrength <- factor(corDat$corrStrength, levels = c('None', 'Weak', 'Moderate', 'Strong'))

corPlot <- ggplot(corDat, aes(daysInProgram, maxDistance)) + 
  geom_point(alpha = 0.7, size = 1) + 
  geom_smooth(method = 'lm', se = F, colour = baseColor) +
  labs(x = 'Days in Program', y = 'Max Distance (miles)')

ann_text <- data.frame(daysInProgram = rep(75, 4),maxDistance = rep(0, 4),
                       lab = c(paste('r =', round(cor.test(noCor$daysInProgram, noCor$maxDistance)$estimate, 2)),
                               paste('r =', round(cor.test(lowCor$daysInProgram, lowCor$maxDistance)$estimate, 2)),
                               paste('r =', round(cor.test(modCor$daysInProgram, modCor$maxDistance)$estimate, 2)),
                               paste('r =', round(cor.test(strCor$daysInProgram, strCor$maxDistance)$estimate, 2))),
                       corrStrength = c('None', 'Weak', 'Moderate', 'Strong'))

ann_text$corrStrength <- factor(ann_text$corrStrength, levels = c('None', 'Weak', 'Moderate', 'Strong'))

corPlot + facet_grid(.~corrStrength) +
  theme(strip.text = element_text(size = 10, face = 'bold')) +
  geom_text(data = ann_text, label = ann_text$lab, size = 4)

```
]

---
## Interpreting $r$

+ The sign of $r$ refers to the direction of the relationship

  + Positive values: the two variables increase or decrease together.
  
  + Negative values: as one variable increases, the other decreases

.pull-left[
```{r, echo = F, fig.height=3.5, fig.width=5, warning = F, message = F}
set.seed(806)
negCor <- rnorm_multi(n=200, mu = c(mean(dat$daysInProgram), mean(dat$maxDistance)), sd = c(sd(dat$daysInProgram),  sd(dat$maxDistance)), varnames = c('daysInProgram', 'maxDistance'), r = -0.5)
negCor$maxDistance[negCor$maxDistance<=0] <- 5

ggplot(negCor, aes(daysInProgram, maxDistance)) + geom_point() + geom_smooth(method = 'lm', se = F, colour = baseColor) + 
  labs(x='Days in Program', y='Max Distance (miles)') +
  scale_y_continuous(breaks = seq(0, 30, 10), limits = c(0, 35)) +
  theme(axis.text = element_text(size = 10), axis.title = element_text(size = 12, face = 'bold')) + 
  annotate('text', label = paste('r =', round(cor.test(negCor$daysInProgram, negCor$maxDistance)$estimate, 2)),
           x=150, y = 30, size = 4)
```
]

.pull-right[
```{r, echo = F, fig.height=3.5, fig.width=5}
ggplot(modCor, aes(daysInProgram, maxDistance)) + geom_point() + geom_smooth(method = 'lm', se = F, colour = baseColor) + 
  labs(x='Days in Program', y = 'Max Distance (miles)') +
  scale_y_continuous(breaks = seq(0, 30, 10), limits = c(0, 35)) +
  theme(axis.text = element_text(size = 10), axis.title = element_text(size = 12, face = 'bold')) + 
  annotate('text', label = paste('r =', round(cor.test(modCor$daysInProgram, modCor$maxDistance)$estimate, 2)), 
           x = 45, y = 30, size = 4)
```
]
  
---

class: center, middle
## Questions?

---

class: inverse, center, middle
# Part 2: Hypothesis Testing with $r$

---

# Hypotheses

+ In some cases, $r$ is considered a descriptive statistic.

  + $r$ is actually a direct measure of effect size:
  
      + It provides information about the strength of the relationship between two variables.
      
      + It is a standardized measure

+ However, there may be times that a correlation is the test of interest, and we can formulate associated hypotheses tests.

---

# Hypotheses

+ There is no real relationship between two random variables, so the null hypothesis should reflect this.

  + $H_0:r=0$

  + $H_{1\ two-tailed}:r\not=0$
  
  + $H_{1\ one-tailed}:r>0\ \lor\ r<0$

---

# Assumptions of Pearson correlation

1. Variables must be interval or ratio (continuous)
  
  + Knowledge of your data
  
  + No Likert Scales!
	

---

# Assumptions of Pearson correlation

1. Variables must be interval or ratio (continuous)
	
2. Variables must be normally distributed.

--

.pull-left[
.center[**Max Distance**]
```{r, echo = F, fig.height=2.5, fig.width=5}
shapiro.test(dat$maxDistance)
ggplot(dat, aes(maxDistance)) + geom_histogram(aes(y=..density..), bins = 18, fill = baseColor, colour = 'darkgray') +
  geom_density() + labs(x='Max Distance', y = 'Density') +
  stat_function(fun = dnorm, args = list(mean = mean(dat$maxDistance), sd = sd(dat$maxDistance)), colour = '#BF1932')
```
]

.pull-right[
.center[**Days in Program**]
```{r, echo = F, fig.height=2.5, fig.width=5}
shapiro.test(dat$daysInProgram)
ggplot(dat, aes(daysInProgram)) + geom_histogram(aes(y=..density..), bins = 18, fill = baseColor, colour = 'darkgray') +
  geom_density() + labs(x='Days in Program', y = 'Density') +
  stat_function(fun = dnorm, args = list(mean = mean(dat$daysInProgram), sd = sd(dat$daysInProgram)), colour = '#BF1932')
```
]

---

# Assumptions of Pearson correlation

1. Variables must be interval or ratio (continuous)
	
2. Variables must be normally distributed.
	
3. There must be no extreme outliers in your data.

--

.pull-left[
.center[**Ok!**]
```{r, echo = F, fig.height=3.25, fig.width=5}
datPlot <- ggplot(dat, aes(daysInProgram, maxDistance)) + geom_point(alpha = 0.5) + 
  geom_smooth(method = 'lm', se = F, colour = baseColor) +
  labs(x='Days in Program', y = 'Max Distance (miles)') +
  scale_x_continuous(breaks=seq(0, 160, 40), limits=c(0, 165)) +
  scale_y_continuous(breaks=seq(0, 30, 10), limits = c(0, 35))

datPlot
```
]

.pull-right[
.center[**Should be investigated**]
```{r, echo = F, fig.height=3.25, fig.width=5}
dat2 <- dat
dat2[nrow(dat2)+1, ] <- c(100, 49)
dat2[nrow(dat2)+1, ] <- c(250, 18)

ggplot(dat2, aes(daysInProgram, maxDistance)) + geom_point(alpha = 0.5) + geom_smooth(method = 'lm', se = F, colour = baseColor) +
  labs(x='Days in Program', y = 'Max Distance (miles)') +
  scale_x_continuous(limits=c(0, 250)) +
  scale_y_continuous(breaks=seq(0, 50, 10)) +
  annotate('point', x=100, y=49, colour="#BF1932") +
  annotate('point', x=250, y=18, colour="#BF1932")
```
]

---

# Assumptions of Pearson correlation

.pull-left[

1. Variables must be interval or ratio (continuous)
	
2. Variables must be normally distributed.
	
3. There must be no extreme outliers in your data.

4. The relationship between the two variables must be linear.

]

--

.pull-right.center[
**Ok!**
```{r, echo = F, fig.height = 2.25, fig.width = 5, message=F}
datPlot
```
<br>
**Should be investigated**
```{r, echo = F, fig.height = 2.25, fig.width = 5, message = F}
nonLinDat <- read.csv('https://uoepsy.github.io/data/anx_perf.csv')
nonLinDat <- nonLinDat[nonLinDat$anxiety<30,]
ggplot(nonLinDat, aes(anxiety, performance)) + geom_point() + geom_smooth(se=F, colour = baseColor)
```
]

---

# Assumptions of Pearson correlation

.pull-left[

1. Variables must be interval or ratio (continuous)
	
2. Variables must be normally distributed.
	
3. There must be no extreme outliers in your data.

4. The relationship between the two variables must be linear.
	
5. Homoscedasticity (homogeneity of variance)   

]

--

.pull-right.center[
**Ok!**
```{r, echo = F, fig.height = 2.25, fig.width = 5, message=F}
datPlot
```
<br>
**Should be investigated**
```{r, echo = F, fig.height = 2.25, fig.width = 5, message = F}
set.seed(113)
dat2 <- rbind(dat, rnorm_multi(n=150, mu=c(130, 18), sd = c(15, 20), varnames = c('daysInProgram', 'maxDistance')))

ggplot(dat2, aes(daysInProgram, maxDistance)) + geom_point(alpha = 0.5) + geom_smooth(method = 'lm', se = F, colour = baseColor) +
  labs(x='Days in Program', y = 'Max Distance (miles)')
```
]

---

# Significance Testing

Remember the key steps of hypothesis testing:

1. Compute a test statistic

2. Locate the test statistic on a distribution that reflects the probability of each test statistic value, given that H0 is true.

3. Determine whether the probability associated with your test statistic is lower than $\alpha$

---

# Significance Testing

**Compute a test statistic**

+ The sampling distribution for $r$ is approximately normal with a large $n$, and is $t$ distributed when $n$ is small.

  + Thus, significance is assessed using a $t$-distribution

--

+ The $t$-statistic for a correlation is calculated as:

$$t=r\sqrt{\frac{n-2}{1-r^2}}$$
+ So in our example:

```{r, echo = F}
rStat <- round(cor.test(dat$daysInProgram, dat$maxDistance)$estimate, 2)
denom <-round(1-(rStat^2),2)
tStat <- as.numeric(round(rStat*(sqrt((nrow(dat)-2)/denom)),2))
pVal <- as.numeric(round(pt(rStat*(sqrt((nrow(dat)-2)/denom)), df = nrow(dat)-2, lower.tail=F), 2))
```

$$t\ =\ `r rStat`\sqrt{\frac{`r nrow(dat)`-2}{1-`r rStat`^2}}\ =\ `r rStat`\sqrt{\frac{`r nrow(dat)-2`}{`r denom`}}\ =\ `r rStat`\sqrt{`r round((nrow(dat)-2)/denom, 2)`}\ =\ `r tStat`$$
---

# Significance Testing

**Locate the test statistic on a distribution**

.pull-left[
+  We use a $t$ distribution with $n-2$ degrees of freedom
  
  + $n-2$: we had to calculate the means of *two* variables (`daysInProgram` and `maxDistance`)

]


.pull-right[
```{r, echo=F, fig.height=3.5, fig.width=5, message = F}
corTestPlot <- ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
  stat_function(fun = dt, args = list(df = nrow(dat)-2), colour = baseColor, size = 1) +
  labs(x='t', y = 'Probability') + 
  annotate(geom = 'text', x = -2, y = 0.3, label = paste('df =',nrow(dat)-2), colour = baseColor, size = 8) +
  theme(axis.text = element_text(size = 12), axis.title = element_text(size = 14, face = 'bold'))

corTestPlot
```
]

---

# Significance Testing

**Locate the test statistic on a distribution**

.pull-left[
+  We use a $t$ distribution with $n-2$ degrees of freedom
  
  + $n-2$: we had to calculate the means of *two* variables (`daysInProgram` and `maxDistance`)

]


.pull-right[
```{r, echo=F, fig.height=3.5, fig.width=5, message = F}
corTestPlot + geom_vline(xintercept=tStat, linetype = 'dashed', color = baseColor)
```
]

---

# Significance Testing

**Determine whether the probability associated with your test statistic is lower than $\alpha$**

.pull-left[

+ We will use two-tailed $\alpha$ = .05

+ The probability of a test statistic at least as extreme as `r tStat` is only `r pVal`. 

+ $`r pVal`<.05$, so we conclude our results are significant.

]

.pull-right[
```{r, echo=F, fig.height=3.5, fig.width=5, message = F, eval = F}
testDat <- seq(tStat, 4, by = .1)
dTest <- dt(testDat, df = nrow(dat)-2)
testDat <- data.frame(vals=testDat, prob=dTest)

corTestPlot + geom_vline(xintercept=tStat, linetype = 'dashed', color = baseColor) +
  geom_area(data = testDat, aes(x=vals,y=prob), fill = baseColor) 
```
]

---

class: center, middle
# Questions?

---

class: inverse, center, middle
# Part 3: Other Types of Correlation

---

# Types of Correlation

| Variable 1  | Variable 2  | Correlation Type |
|-------------|-------------|------------------|
| Continuous  | Continuous  | Pearson          |
| Continuous  | Categorical | Polyserial       |
| Continuous  | Binary      | Biserial         |
| Categorical | Categorical | Polychoric       |
| Binary      | Binary      | Tetrachoric      |
| Rank        | Rank        | Spearman         |
| Nominal     | Nominal     | Chi-square       |


---
# Spearman's Correlation

+ Spearman's $\rho$ (or rank-order correlation) uses data on the rank-ordering of $x$, $y$ responses for each individual.
  
+ Spearman's $\rho$ is a nonparametric version of Pearson's $r$, so it doesn't require the same constraints on your data

+ When would we choose to use the Spearman correlation?
	+ If our data are naturally ranked data (e.g. a survey where the task is to rank foods and drinks in terms of preference)
	+ Our data are ordinal (e.g., Likert Scales)
	+ If the data are non-normal or skewed
	+ If the data shows evidence of non-linearity

---
# Spearman's Correlation

+ Spearman's is not testing for linear relations, it is testing for increasing monotonic relationship.

--

  + What?

--

.pull-left.center[
**Linear**
```{r, echo = F, fig.height=3.5, fig.width=5}
mono <- tibble(
  A = c(1,2,3,4,5,6,7,8,9,10),
  B = c(1,2,3,4,5,6,7,8,9,10),
  C = c(1,4,5,6,8,9,10,13,15,16)
)

lp <- mono %>%
  ggplot(., aes(x=A, y=B)) +
  geom_point() + 
  geom_line()

mp <- mono %>%
  ggplot(., aes(x=A, y=C)) +
  geom_point() + 
  geom_line()

lp
```
<br>
A perfectly linear relationship between A & B

]

.pull-right.center[
**Increasing Monotonic**
```{r, echo = F, fig.height=3.5, fig.width=5}
mp
```
<br>
A perfectly increasing monotonic relationship between A & C
]

---
# Monotonic Relationship

+ **Perfect Monotonic Relationship:** The rank position of all observations on Variable A is the same as the rank position of all observations on Variable C.

.pull-left[

```{r, echo = F}
tibble(
  A = c(1,2,3,4,5,6,7,8,9,10),
  B = c(1,2,3,4,5,6,7,8,9,10),
  C = c(1,4,5,6,8,9,10,13,15,16)
) %>%
  mutate(
    ID = paste("ID", 1:10, sep = ""),
    Rank_A = rank(A),
    Rank_C = rank(C)
  ) %>%
  dplyr::select(., ID, A, C, Rank_A, Rank_C) %>%
  kable() %>%
  kable_styling(full_width = F)

```

]

.pull-right[
```{r, echo = F, fig.height=3.5, fig.width=5}
mp
```

]

---

# Calculating Spearman's $\rho$

$$\rho=1-\frac{6\sum{d^2_i}}{n(n^2-1)}$$
+ $d_i=$ rank( $x_i$ ) $-$ rank( $y_i$ )

+ Steps
  1. Rank each variable from largest to smallest 
  2. Calculate the difference in rank for each person on the two variables
  3. Square the difference
  4. Sum the squared values

---

# Calculating Spearman's $\rho$ in R

+ You can also use `cor()` and `cor.test()` to calculate Spearman's $\rho$ in R:

+ Imagine we want to know whether the participants' ratings (on a 1-5 scale) of the program are associated with how difficult they found the program (on a 1-5 scale).

.pull-left[
<br>
```{r, echo = F}
ratings <- tibble(Names=sampleDat$Names, ProgRating=c(3, 5, 4, 2, 4, 3, 2), Difficulty=c(2, 3, 2, 5, 3, 1, 4))
kable(ratings)
```
]

--

.pull-left[
```{r}
cor(ratings$ProgRating, ratings$Difficulty,
    method='spearman')

cor.test(ratings$ProgRating, ratings$Difficulty,
         method='spearman')
```

]

---

class: center, middle, inverse
# Questions?

---

class: center, middle
# Thanks for Listening!
